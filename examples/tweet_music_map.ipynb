{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tweet_parser.tweet import Tweet\n",
    "from tweet_parser.getter_methods.tweet_geo import get_profile_location\n",
    "\n",
    "from twittersearch.result_stream import ResultStream\n",
    "from twittersearch.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = \"agonzales@twitter.com\"\n",
    "search_api = \"fullarchive\"\n",
    "account_name = \"shendrickson\"\n",
    "endpoint_label = \"ogformat.json\"\n",
    "\n",
    "search_endpoint = gen_endpoint(search_api, account_name, endpoint_label, count_endpoint=False)\n",
    "count_endpoint = gen_endpoint(search_api, account_name, endpoint_label, count_endpoint=True)\n",
    "\n",
    "search_args = {\"username\": username, \"password\": pw, \"url\": search_endpoint }\n",
    "count_args = {\"username\": username, \"password\": pw, \"url\": count_endpoint }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rule = \"\"\"\n",
    "\"taylor swift\"\n",
    "has:geo\n",
    "or \n",
    "has:profile_geo\n",
    "\"\"\"\n",
    "\n",
    "count_rule = gen_rule_payload(_rule,\n",
    "                        from_date=\"2016-09-01\",\n",
    "                        to_date=\"2017-09-01\",\n",
    "                        max_results=500, \n",
    "                        count_bucket=\"day\")\n",
    "\n",
    "search_rule = gen_rule_payload(_rule,\n",
    "                        from_date=\"2016-09-01\",\n",
    "                        to_date=\"2017-09-01\",\n",
    "                        max_results=500, \n",
    "                        )\n",
    "rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = list(ResultStream(**count_args, rule_payload=rule, max_tweets=1000).stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(counts)\n",
    " .assign(timePeriod=lambda df: pd.to_datetime(df[\"timePeriod\"]))\n",
    " .set_index(\"timePeriod\")\n",
    " .sort_index()\n",
    " .plot()\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(ResultStream(**search_args, rule_payload=search_rule, max_tweets=500).stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tweets[0]\n",
    "t.text\n",
    "t.profile_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_geo_collector(result_stream, tag, fields=None):\n",
    "    if fields is None:\n",
    "        fields = [\"id\", \"created_at_datetime\", \"text\"]\n",
    "    \n",
    "    coords = []\n",
    "    print(\"collecting tweets for {}\".format(tag))\n",
    "    for tweet in result_stream.stream():\n",
    "        attrs = (tweet.__getattribute__(field)\n",
    "                   for field in fields)\n",
    "        try:\n",
    "            _coords = get_a_geo_coordinate(tweet)\n",
    "            coords.append(list(it.chain.from_iterable([attrs, _coords])))\n",
    "        except AttributeError:\n",
    "            print(\"error in geo\")\n",
    "            print(tweet.id, tweet.text)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    result_stream.end_stream()\n",
    "    columns = list(it.chain.from_iterable([fields, [\"lat\", \"long\"]]))\n",
    "    \n",
    "    df = (pd.DataFrame(coords, columns=columns)\n",
    "          .pipe(latlng_to_meters, \"lat\", \"long\")\n",
    "          .drop([\"lat\", \"long\"], axis=1)\n",
    "          .assign(tag=tag)\n",
    "         )\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ResultStream(**as_args, rule_payload=rule, max_results=500, )\n",
    "# rs.artist = \"taylor_swift\"\n",
    "df = tweet_geo_collector(rs, tag=\"taylor_swift\", fields=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter_point(lat, long, pct=10):\n",
    "    \n",
    "    return np.random.uniform(lat, long)\n",
    "\n",
    "def jitter_box(lat, long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from tweet_parser.tweet_checking import is_original_format\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    mean_bbox = lambda x: list(np.array(x).mean(axis=0))\n",
    "except ImportError:\n",
    "    mean_bbox = lambda x: (reduce(lambda y, z: y + z, x) / len(x))\n",
    "\n",
    "def get_profile_geo_coords(tweet):\n",
    "    geo = tweet.profile_location.get(\"geo\")\n",
    "    coords = geo.get(\"coordinates\") # in [LONG, LAT]\n",
    "    if coords:\n",
    "        long, lat = coords\n",
    "    return lat, long\n",
    "\n",
    "\n",
    "def get_place_coords(tweet, est_center=False):\n",
    "    \"\"\"\n",
    "    Places are formal spots that define a bounding box around a place.\n",
    "    Each coordinate pair in the bounding box is a set of [[lat, long], [lat, long]]\n",
    "    pairs.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def get_bbox_ogformat():\n",
    "        _place = tweet.get(\"place\")\n",
    "        if _place is None:\n",
    "            return None\n",
    "    \n",
    "        return (_place\n",
    "                .get(\"bounding_box\")\n",
    "                .get(\"coordinates\")[0])\n",
    "\n",
    "    def get_bbox_asformat():\n",
    "        _place = tweet.get(\"location\")\n",
    "        if _place is None:\n",
    "            return None\n",
    "        return (_place\n",
    "                .get(\"geo\")\n",
    "                .get(\"coordinates\")[0])\n",
    "        \n",
    "    bbox = get_bbox_ogformat() if is_original_format(tweet) else get_bbox_asformat()\n",
    "\n",
    "    return mean_bbox(bbox) if est_center else bbox\n",
    "\n",
    "\n",
    "def get_exact_geo_coords(tweet):\n",
    "    geo = tweet.get(\"geo\")\n",
    "    if geo is None:\n",
    "        return None\n",
    "    \n",
    "    # coordinates.coordinates is [LONG, LAT]\n",
    "    # geo.coordinates is [LAT, LONG]\n",
    "    field = \"geo\" if is_original_format(tweet) else \"geo\"\n",
    "    coords = tweet.get(\"geo\").get(\"coordinates\")\n",
    "    return coords\n",
    "\n",
    "\n",
    "def get_a_geo_coordinate(tweet):\n",
    "    geo = get_exact_geo_coords(tweet)\n",
    "    lat, long = geo if geo else (None, None)\n",
    "    if lat:\n",
    "        return lat, long\n",
    "    long, lat = get_place_coords(tweet, est_center=True)\n",
    "    return lat, long\n",
    "\n",
    "\n",
    "def latlng_to_meters(df, lat_name, lng_name):\n",
    "    \"\"\"\n",
    "    Taken and modified from the datashader notebooks \n",
    "    \"\"\"\n",
    "    lat = df[lat_name]\n",
    "    lng = df[lng_name]\n",
    "    origin_shift = 2 * np.pi * 6378137 / 2.0\n",
    "    mx = lng * origin_shift / 180.0\n",
    "    my = np.log(np.tan((90 + lat) * np.pi / 360.0)) / (np.pi / 180.0)\n",
    "    my = my * origin_shift / 180.0\n",
    "    return df.assign(mx=mx).assign(my=my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bokeh.models import WMTSTileSource\n",
    "from bokeh.tile_providers import STAMEN_TONER\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import ColumnDataSource, figure\n",
    "from bokeh.models import HoverTool, value\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "tiles = {'OpenMap': WMTSTileSource(url='http://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png'),\n",
    "         'ESRI': WMTSTileSource(url='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'),\n",
    "         'Wikipedia': WMTSTileSource(url='https://maps.wikimedia.org/osm-intl/{Z}/{X}/{Y}@2x.png'),\n",
    "         'Stamen': WMTSTileSource(url=\"http://tile.stamen.com/toner-background/{z}/{x}/{y}.png\")\n",
    "         }\n",
    "\n",
    "\n",
    "def plot_tweets(df, x_col=\"mx\", y_col=\"my\", tile=\"Stamen\", title=\"title\"):\n",
    "    # add our DataFrame as a ColumnDataSource for Bokeh\n",
    "    plot_data = ColumnDataSource(df)\n",
    "    # create the plot and configure the\n",
    "    # title, dimensions, and tools\n",
    "    plot = figure(title=title,\n",
    "                  plot_width=800,\n",
    "                  plot_height=800,\n",
    "                  tools= ('pan, wheel_zoom, box_zoom, reset'),\n",
    "                  active_scroll='wheel_zoom')\n",
    "\n",
    "    # add a hover tool to display words on roll-over\n",
    "    plot.add_tools(HoverTool(tooltips = '@text'))\n",
    "\n",
    "    # draw the words as circles on the plot\n",
    "    plot.circle(x=x_col, y=y_col, source=plot_data,\n",
    "                     color=u'blue', line_alpha=0.1, fill_alpha=0.1,\n",
    "                     size=3, hover_line_color='black')\n",
    "\n",
    "    # configure visual elements of the plot\n",
    "    plot.title.text_font_size = value('12pt')\n",
    "    plot.xaxis.visible = False\n",
    "    plot.yaxis.visible = False\n",
    "    plot.grid.grid_line_color = None\n",
    "    plot.outline_line_color = None\n",
    "    plot.add_tile(tiles[tile])\n",
    "    return plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def gen_multipart(rules):\n",
    "    rules = ['(\"{}\")'.format(rule) for rule in rules]\n",
    "    return \"({}) has:geo place_country:us\".format(' OR '.join(rules))\n",
    "\n",
    "gen_rule = partial(gen_rule_payload,\n",
    "                   max_results=500,\n",
    "                   from_date=\"2016-09-01\",\n",
    "                   to_date=\"2017-09-01\",\n",
    "                   )\n",
    "base_rule = \"\"\"\n",
    "\"{}\"\n",
    "has:geo\n",
    "place_country:us\n",
    "\"\"\"\n",
    "\n",
    "artists = [\"taylor swift\",\n",
    "           \"uzi vert\",\n",
    "           \"beyonce\",\n",
    "           \"luke bryan\",\n",
    "           \"eminem\"\n",
    "          ]\n",
    "\n",
    "artist_dicts = {\"taylor swift\": [\"taylor swift\",\n",
    "                                 \"look what you made me do\",\n",
    "                                 ],\n",
    "                \n",
    "                \"uzi vert\": [\"uzi vert\", \"lil uzi\", \"lil uzi vert\", \n",
    "                             \"XO TOUR Lif3\", \"money longer\"],\n",
    "                \"beyonce\": [\"beyonce\", \"formation\",\n",
    "                            \"queen bey\", \"bey\", \"beyonc√©\",\n",
    "                            \"halo\", \"crazy in love\"],\n",
    "                \"luke bryan\": [\"luke bryan\", \"huntin fishin lovin\", \"play it again\"],\n",
    "                \"eminem\": [\"eminem\", \"love the way you lie\", \"rap god\", \"lose yourself\"]\n",
    "                \n",
    "               }\n",
    "_tweet_collector = partial(tweet_geo_collector, fields=[\"id\"])\n",
    "\n",
    "artist_rules = [gen_rule(gen_multipart(v)) for k, v in artist_dicts.items()]\n",
    "\n",
    "artist_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(ResultStream(**search_args, rule_payload=artist_rules[3]).stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets[20].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streams = [ResultStream(**as_args,\n",
    "                        rule_payload=rule,\n",
    "                        max_results=100000)\n",
    "           for rule in artist_rules]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [tweet_geo_collector(stream, tag) for stream, tag in zip(streams, artists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"tag == 'beyonce'\").sort_values(\"created_at_datetime\", ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .set_index(\"created_at_datetime\")\n",
    " .sort_index()\n",
    " .groupby([pd.TimeGrouper(\"D\"), \"tag\"])\n",
    " .size()\n",
    " .to_frame(\"tweets\")\n",
    " [\"tweets\"]\n",
    " .unstack()\n",
    " .fillna(0)\n",
    " .plot()\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def even_sample(df, cat_col):\n",
    "    cats = df[cat_col].unique()\n",
    "    vc = df[cat_col].value_counts()\n",
    "    min_count = vc.min()\n",
    "    res = []\n",
    "    for cat in cats:\n",
    "        res.append(df[df[cat_col] == cat].sample(min_count))\n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "even_df = even_sample(df, \"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.models.widgets import Panel, Tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_chainz = plot_tweets(df.query(\"tag == '2 chainz'\"))\n",
    "ku = plot_tweets(df.query(\"tag == 'keith urban'\"))\n",
    "ts = plot_tweets(df.query(\"tag == 'taylor swift'\"))\n",
    "bey = plot_tweets(df.query(\"tag == 'beyonce'\"))\n",
    "\n",
    "tabs = Tabs(tabs=[Panel(child=two_chainz, title=\"2 chainz\"),\n",
    "                 # Panel(child=ku, title=\"keith urban\"),\n",
    "                  Panel(child=ts, title=\"taylor swift\"),\n",
    "                 # Panel(child=bey, title=\"beyonce\")\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, reset_output, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_output()\n",
    "# output_file(\"bokeh_tabs.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file(\"test_bokeh.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(tabs, filename=\"test_bokeh.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datashader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh import palettes\n",
    "\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "\n",
    "from datashader.bokeh_ext import InteractiveImage\n",
    "\n",
    "from cartopy import crs\n",
    "\n",
    "\n",
    "import geoviews as gv\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "from holoviews.operation.datashader import aggregate, shade, datashade, dynspread\n",
    "\n",
    "\n",
    "hv.notebook_extension('mpl', 'bokeh')\n",
    "\n",
    "\n",
    "def gen_col_points(categories, colormap):\n",
    "    inv_cats = {k: k for k in categories}\n",
    "    color_points = hv.NdOverlay({inv_cats[k]: gv.Points([0,0],\n",
    "                                                        crs=crs.PlateCarree(),\n",
    "                                                        label=inv_cats[k])\n",
    "                                 (style=dict(color=v))\n",
    "                                 for k, v in colormap.items()})\n",
    "    return color_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_df = df.assign(tag=lambda df: df[\"tag\"].astype(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_min, y_min, x_max, y_max = (plot_df.mx.values.min(),\n",
    "                              plot_df.my.values.min(),\n",
    "                              plot_df.mx.values.max(),\n",
    "                              plot_df.my.values.max())\n",
    "x_range=(x_min, x_max)\n",
    "y_range=(y_min, y_max)\n",
    "color_key = dict(zip(artists, palettes.Category10[len(artists)]))\n",
    "shade_defaults = dict(x_range=x_range,\n",
    "                      y_range=y_range,\n",
    "                      width=1200,\n",
    "                      height=660)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output filename=\"artist_datashaded_points\"\n",
    "%%opts Overlay [width=800 height=600 xaxis=None yaxis=None show_grid=False ] (background_alpha=0.1) \n",
    "%%opts Shape (fill_color=None line_width=1.5) [apply_ranges=False] \n",
    "%%opts Points [apply_ranges=False tools=[]]\n",
    "%%opts WMTS (alpha=0.25)\n",
    "\n",
    "# shade_defaults = dict(x_range=(x_max, x_min),\n",
    "                      # y_range=(y_max, y_min),\n",
    "                      # width=1200,\n",
    "                      # height=660)\n",
    "\n",
    "shaded_points = datashade(hv.Points(gv.Dataset(plot_df,\n",
    "                                               kdims=[\"mx\", \"my\"],\n",
    "                                               vdims=[\"tag\"])),\n",
    "                          cmap=color_key,\n",
    "                          element_type=gv.Image,\n",
    "                          aggregator=ds.count_cat(\"tag\"),\n",
    "                          **shade_defaults, \n",
    "                         )\n",
    "\n",
    "color_points = gen_col_points(color_key.keys(), color_key)\n",
    "\n",
    "map_ = gv.WMTS(tiles[\"Stamen\"]) * dynspread(shaded_points,\n",
    "                                            max_px=1,\n",
    "                                            threshold=0.5) * color_points\n",
    "map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
