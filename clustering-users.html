<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Learning More With Twitter Data &#8212; Twitter Search APIs Python Wrapper 1.0b documentation</title>
    
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0b',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-30775-108"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-30775-108');
  </script>


  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          Twitter Search API</a>
        <span class="navbar-text navbar-version pull-left"><b>1.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="https://github.com/twitterdev/twitter_search_api">Github</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Twitter Search API <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Python Twitter Search API</a></li>
<li class="toctree-l1"><a class="reference internal" href="searchtweets.html">searchtweets package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="searchtweets.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="searchtweets.html#module-searchtweets.api_utils">searchtweets.api_utils module</a></li>
<li class="toctree-l2"><a class="reference internal" href="searchtweets.html#module-searchtweets.result_stream">searchtweets.result_stream module</a></li>
<li class="toctree-l2"><a class="reference internal" href="searchtweets.html#module-searchtweets.utils">searchtweets.utils module</a></li>
<li class="toctree-l2"><a class="reference internal" href="searchtweets.html#module-searchtweets">Module contents</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Learning More With Twitter Data</a><ul>
<li><a class="reference internal" href="#clustering-twitter-users"><em>Clustering Twitter Users</em></a><ul>
<li><a class="reference internal" href="#intro">Intro</a><ul>
<li><a class="reference internal" href="#caveat">Caveat</a><ul>
<li><a class="reference internal" href="#running-this-notebook">Running This Notebook</a></li>
<li><a class="reference internal" href="#environment-setup">Environment Setup</a><ul>
<li><a class="reference internal" href="#data-collection">Data Collection</a></li>
</ul>
</li>
<li><a class="reference internal" href="#api-setup">API setup</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#data-inspection">Data Inspection</a></li>
</ul>
</li>
<li><a class="reference internal" href="#feature-engineering">Feature Engineering</a><ul>
<li><a class="reference internal" href="#source-data">Source data</a></li>
<li><a class="reference internal" href="#preprocessing">Preprocessing</a></li>
<li><a class="reference internal" href="#handling-urls">Handling URLs</a></li>
<li><a class="reference internal" href="#tokenization">Tokenization</a></li>
<li><a class="reference internal" href="#remove-stopwords">Remove Stopwords</a></li>
<li><a class="reference internal" href="#vectorization">Vectorization</a></li>
<li><a class="reference internal" href="#selecting-and-tuning-a-model">Selecting and tuning a model</a></li>
</ul>
</li>
<li><a class="reference internal" href="#inspecting-model-results">Inspecting model results</a><ul>
<li><a class="reference internal" href="#population-sizes">Population sizes</a></li>
<li><a class="reference internal" href="#cluster-text-association">Cluster-text association</a></li>
<li><a class="reference internal" href="#visualization">Visualization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-iteration">Model iteration</a><ul>
<li><a class="reference internal" href="#hdbscan">HDBSCAN</a></li>
<li><a class="reference internal" href="#populations-sizes">Populations sizes</a></li>
<li><a class="reference internal" href="#id1">Cluster-text association</a></li>
<li><a class="reference internal" href="#id2">Visualization</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="learning-more-with-twitter-data">
<h1>Learning More With Twitter Data<a class="headerlink" href="#learning-more-with-twitter-data" title="Permalink to this headline">¬∂</a></h1>
<p>Twitter is what's happening and what people are talking about right now, with
hundreds of millions of Tweets sent each day. We're a group of data scientists
on the Twitter Data team who are helping people do more with this vast amount
of data in less time. In this spirit, we are starting a series of tutorials
that aim to help people work with Twitter data effectively. Each of the posts
in this series centers around a real-life example project and provides
MIT-licensed code that you can use to bootstrap your projects with our
enterprise and premium API products. We hope this series is fruitful for you
and we are excited to see what you&#8217;ll build.</p>
<div class="section" id="clustering-twitter-users">
<h2><em>Clustering Twitter Users</em><a class="headerlink" href="#clustering-twitter-users" title="Permalink to this headline">¬∂</a></h2>
<p>&#8211; by Josh Montague <a class="reference external" href="https://twitter.com/jrmontag/">(&#64;jrmontag)</a>, Jan 2018</p>
<div class="section" id="intro">
<h3>Intro<a class="headerlink" href="#intro" title="Permalink to this headline">¬∂</a></h3>
<p>Often, when people think about conducting analysis on data from Twitter,
they think analyzing Tweet content. While this is a rich collection of
data, another important dimension in which to think about Twitter data
analysis is that of its <em>users</em>.</p>
<p>Twitter users post all sorts of interesting content in Tweets, but they
also frequently share information about themselves by way of their
account profile. If you visit <a class="reference external" href="https://twitter.com/jrmontag">this author&#8217;s
profile</a>, you&#8217;ll find a handful of data
points that are not Tweet-related, but user-related. Among other things,
you might find geographical data, pointers to other websites, and a
free-text profile description e.g. &#8220;counts üê•üí¨, drinks ‚òïÔ∏è, takes üì∑,
climbs üóª&#8221;. This is data that a user may not regularly Tweet about, and
which you would miss if you were only looking at their posted content.</p>
<p>In this demo, we&#8217;re going to look at how to use the Twitter Search APIs
to collect data around a cultural topic, and then use the resulting data
to learn something interesting about the users participating in that
discussion. Specifically, we&#8217;ll look for clusters of similar users among
all of the users we identify. Along the way, we&#8217;ll look at some of the
ways that you can make the journey from the collection of JSON data,
processing relevant elements of each Tweet, engineering features that
can used for model training, and finally, inspecting the results of our
models to see what we&#8217;ve learned.</p>
<div class="section" id="caveat">
<h4>Caveat<a class="headerlink" href="#caveat" title="Permalink to this headline">¬∂</a></h4>
<p>This post is not meant to be a tutorial in Python or the PyData
ecosystem and assumes that readers have a reasonable amount of technical
sophistication. This tutorial uses Python because our group makes heavy
use of the PyData stack (python, pandas, numpy, scikit-learn, etc.), but
the following techniques can be applied in any language with decent
machine-learning and data processing library support.</p>
<p>This notebook will follow the outline below:</p>
<ul class="simple">
<li>data collection</li>
<li>data inspection</li>
<li>feature engineering<ul>
<li>source data</li>
<li>preprocessing</li>
<li>tokenization</li>
<li>stopwords</li>
<li>vectorization</li>
</ul>
</li>
<li>selecting and tuning a model</li>
<li>inspecting a model</li>
<li>model iteration</li>
</ul>
<div class="section" id="running-this-notebook">
<h5>Running This Notebook<a class="headerlink" href="#running-this-notebook" title="Permalink to this headline">¬∂</a></h5>
<p>If you want to run this notebook, it is hosted
<a class="reference external" href="https://github.com/twitterdev/learning_more_with_twitter_data">here</a>.
Clone this repo and you&#8217;ll see this notebook in the <code class="docutils literal"><span class="pre">clustering-users</span></code>
directory. Please see the accompanying <code class="docutils literal"><span class="pre">README.md</span></code> file for full
instructions. We&#8217;ve provided both a pip-ready
<code class="docutils literal"><span class="pre">clustering_requirements.txt</span></code> file and a conda environment file,
<code class="docutils literal"><span class="pre">clustering_users_conda_env.yml</span></code> that allows an easy virtual
environment for this example. This example assumes python 3.6.</p>
</div>
<div class="section" id="environment-setup">
<h5>Environment Setup<a class="headerlink" href="#environment-setup" title="Permalink to this headline">¬∂</a></h5>
<p>First, some imports.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">itertools</span> <span class="k">as</span> <span class="nn">it</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">bokeh.plotting</span> <span class="k">import</span> <span class="n">figure</span><span class="p">,</span> <span class="n">ColumnDataSource</span><span class="p">,</span> <span class="n">show</span><span class="p">,</span> <span class="n">output_notebook</span><span class="p">;</span> <span class="n">output_notebook</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">bokeh.models</span> <span class="k">import</span> <span class="n">HoverTool</span>
<span class="kn">from</span> <span class="nn">bokeh.palettes</span> <span class="k">import</span> <span class="n">brewer</span><span class="p">,</span> <span class="n">Viridis256</span>
<span class="kn">import</span> <span class="nn">hdbscan</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="k">import</span> <span class="n">everygrams</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize.casual</span> <span class="k">import</span> <span class="n">TweetTokenizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="k">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">silhouette_score</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">TruncatedSVD</span>
<span class="kn">from</span> <span class="nn">stop_words</span> <span class="k">import</span> <span class="n">get_stop_words</span>
<span class="kn">from</span> <span class="nn">tweet_parser.tweet</span> <span class="k">import</span> <span class="n">Tweet</span>
<span class="kn">from</span> <span class="nn">searchtweets</span> <span class="k">import</span> <span class="n">load_credentials</span><span class="p">,</span> <span class="n">gen_rule_payload</span><span class="p">,</span> <span class="n">collect_results</span>
<span class="kn">from</span> <span class="nn">MulticoreTSNE</span> <span class="k">import</span> <span class="n">MulticoreTSNE</span> <span class="k">as</span> <span class="n">TSNE</span>
<span class="kn">import</span> <span class="nn">yaml</span>

<span class="c1"># better viewing of tweet text</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>

<span class="c1"># reproducible rng</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;bmh&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>
</div>
<div class="bk-root">
    <a href="https://bokeh.pydata.org" target="_blank" class="bk-logo bk-logo-small bk-logo-notebook"></a>
    <span id="0aafd301-c04d-49e1-9927-719c28388fb3">Loading BokehJS ...</span>
</div><div class="section" id="data-collection">
<h6>Data Collection<a class="headerlink" href="#data-collection" title="Permalink to this headline">¬∂</a></h6>
<p>For a detailed walk-through of how to interact with the Search APIs, how
to construct filters, and more of the nuances of iterative
filter-building, you should first review <a class="reference external" href="TODO">this notebook</a>. In
this example, we&#8217;ll assume the reader has enough familiarity that we can
quickly choose a topic, create our first rule, and programatically
interacting with the API to refine the rule.</p>
<p>We&#8217;ll use the <a class="reference external" href="https://en.wikipedia.org/wiki/Cannes_Film_Festival">2017 Cannes Film
Festival</a> as our
topic. Ultimately we are interested in those users who are Tweeting
about the festival, so we start by looking for relevant Tweets and then
we&#8217;ll dig into the users behind those Tweets.</p>
<p>When in doubt, it&#8217;s a reasonable strategy to start broad and simple with
our rule - in this case we can simply use &#8220;cannes&#8221;. After inspecting the
data we can refine the rule (and resulting data) in the name of
increasing it&#8217;s relevance to the task at hand.</p>
</div>
</div>
<div class="section" id="api-setup">
<h5>API setup<a class="headerlink" href="#api-setup" title="Permalink to this headline">¬∂</a></h5>
<p>Our tools handle authentication by keeping credentials in a YAML file.
Please go ahead and make a YAML file named <code class="docutils literal"><span class="pre">.twitter_keys.yaml</span></code> in
your home directory that looks like this:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">search_tweets_api</span><span class="p">:</span>
  <span class="n">endpoint</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">FULL_URL_OF_ENDPOINT</span><span class="o">&gt;</span>
  <span class="n">account</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">ACCOUNT_NAME</span><span class="o">&gt;</span>
  <span class="n">username</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">USERNAME</span><span class="o">&gt;</span>
  <span class="n">password</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PW</span><span class="o">&gt;</span>
  <span class="n">bearer_token</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">TOKEN</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>The rest of the example will assume <code class="docutils literal"><span class="pre">~/.twitter_keys.yaml</span></code> exists,
though you can specify your connection information directing in the
notebook or using an environment variable if you want.</p>
<p>If you are a premium user (or testing out premium), please set
<code class="docutils literal"><span class="pre">bearer_token</span></code>. If you have an enterprise account, please set your
account name and password.</p>
<p>The <code class="docutils literal"><span class="pre">load_credentials</span></code> function parses this file and we&#8217;ll save the
<code class="docutils literal"><span class="pre">search_args</span></code> variable for use throughout the session.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">search_args</span> <span class="o">=</span> <span class="n">load_credentials</span><span class="p">(</span><span class="n">account_type</span><span class="o">=</span><span class="s2">&quot;enterprise&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The 2017 festival lasted from 2017-05-17 to 2017-05-29. Our simple rule
will likely generate a lot of data in that time range, so we&#8217;ll limit
our queries by the number of Tweets to start. We can still use these
dates in our rule, and later we&#8217;ll just adjust the Tweet limit.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># the festival was 2017-05-17 -- 2017-05-29</span>
<span class="n">rule</span> <span class="o">=</span> <span class="n">gen_rule_payload</span><span class="p">(</span><span class="s1">&#39;cannes&#39;</span><span class="p">,</span> <span class="n">from_date</span><span class="o">=</span><span class="s1">&#39;2017-05-17&#39;</span><span class="p">,</span> <span class="n">to_date</span><span class="o">=</span><span class="s1">&#39;2017-05-29&#39;</span><span class="p">)</span>

<span class="n">rule</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;{&quot;query&quot;: &quot;cannes&quot;, &quot;maxResults&quot;: 500, &quot;toDate&quot;: &quot;201705290000&quot;, &quot;fromDate&quot;: &quot;201705170000&quot;}&#39;</span>
</pre></div>
</div>
<p>We can pass the rule and our limit of 1000 Tweets to the API, and
collect the results into memory. For convenience, we&#8217;ll also write them
to disk as newline-delimited JSON, too. This is handy in case we want to
come back to the same data later - we won&#8217;t need to make new API
requests.</p>
<p>The following function will define our entry point to get our Tweet
data, and will automatically read or collect the data from the API and
save it to the passed filename.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">maybe_get_tweets</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_results</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">tweets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">infile</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;reading cached tweets&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">infile</span><span class="p">:</span>
                <span class="n">tweets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Tweet</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)))</span>

    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">rule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;collecting tweets from the API&quot;</span><span class="p">)</span>
            <span class="n">tweets</span> <span class="o">=</span> <span class="n">collect_results</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span>
                                     <span class="n">max_results</span><span class="o">=</span><span class="n">max_results</span><span class="p">,</span>
                                     <span class="n">result_stream_args</span><span class="o">=</span><span class="n">search_args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;rule is not defined; please supply a valid rule for the query&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">KeyError</span>
        <span class="c1"># write sample to disk</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">outfile</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">tw</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">:</span>
                <span class="n">outfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">tw</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tweets</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tweets</span> <span class="o">=</span> <span class="n">maybe_get_tweets</span><span class="p">(</span><span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;data/sample-cannes.json&quot;</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="n">rule</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">reading</span> <span class="n">cached</span> <span class="n">tweets</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">1000</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># quick check of one payload</span>
<span class="n">tweets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;RT @PurelyPattinson: NEW pictures of Rob in Cannes last night. (Via @AboutRPattinson) https://t.co/w5P7PilHwc&#39;</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-inspection">
<h3>Data Inspection<a class="headerlink" href="#data-inspection" title="Permalink to this headline">¬∂</a></h3>
<p>Great, now we have some data to work with. Importantly, the first step
is always to inspect the data. Is it what you were expecting? Is it
relevant? Are there sources of noise you can negate in your rule? All of
these issues can be addressed by iterating on your filters and
inspecting the results.</p>
<p>Additionally, since we intentionally capped the number of total Tweets,
it&#8217;s good to inspect the time series of data to see what range it
covers.</p>
<p>Since Tweets are automatically parsed with the <a class="reference external" href="https://twitterdev.github.io/tweet_parser/index.html">Tweet
Parser</a> in our
Python session, we can use some of the convenient attributes to pull out
the text data.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tweets_to_df</span><span class="p">(</span><span class="n">tweets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper func to extract specific tweet features into a dataframe.&quot;&quot;&quot;</span>
    <span class="n">tweet_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;ts&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">created_at_datetime</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">],</span>
                             <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">all_text</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">],</span>
                             <span class="s1">&#39;uid&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">user_id</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">],}</span>
                           <span class="p">)</span>
    <span class="c1"># creating a datetimeindex will allow us to do more timeseries manipulations</span>
    <span class="n">tweet_df</span><span class="p">[</span><span class="s1">&#39;ts&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">tweet_df</span><span class="p">[</span><span class="s1">&#39;ts&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tweet_df</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tweet_df</span> <span class="o">=</span> <span class="n">tweets_to_df</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>

<span class="n">tweet_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>ts</th>
      <th>uid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NEW pictures of Rob in Cannes last night. (Via @AboutRPattinson) https://t.co/w5P7PilHwc</td>
      <td>2017-05-28 23:59:58</td>
      <td>711474468</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Hasta hoy solo dos mujeres ganaron el premio a la mejor direcci√≥n en Cannes... https://t.co/0dYh2OrsDS #lacosacine</td>
      <td>2017-05-28 23:59:58</td>
      <td>153826105</td>
    </tr>
    <tr>
      <th>2</th>
      <td>juliette binoche wearing armani dresses at cannes,, rt if you agree https://t.co/vAuXtjjxZv</td>
      <td>2017-05-28 23:59:56</td>
      <td>3179550766</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Aishwarya Rai Bachchan is the Queen of the Cannes Film Festival üëëüëëüëë https://t.co/sLsIwxDWFw</td>
      <td>2017-05-28 23:59:54</td>
      <td>314300800</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cannes Film Festival\n‚ÄòThe Square‚Äô Wins Top Prize at @Festival_Cannes\nSofia Coppola ("The Beguiled") Is Best Director\nhttps://t.co/RZilOXxQcV ht...</td>
      <td>2017-05-28 23:59:54</td>
      <td>713888098313224192</td>
    </tr>
  </tbody>
</table>
</div><div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># plot a time series</span>
<span class="p">(</span><span class="n">tweet_df</span><span class="p">[[</span><span class="s1">&#39;ts&#39;</span><span class="p">,</span><span class="s1">&#39;text&#39;</span><span class="p">]]</span>
 <span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;ts&#39;</span><span class="p">)</span>
 <span class="c1"># &#39;T&#39; = minute</span>
 <span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
 <span class="o">.</span><span class="n">count</span><span class="p">()</span>
 <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;1-minute counts&#39;</span><span class="p">))</span>
 <span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="p">);</span>
</pre></div>
</div>
<img alt="_images/clustering-users_16_0.png" src="_images/clustering-users_16_0.png" />
<p>Given the <code class="docutils literal"><span class="pre">max_results</span></code> we added, we have a very short time span for
now. Our data collection starts at the end date, and works backward
until hitting the maximum result count. But that&#8217;s ok, we&#8217;ll collect
more data later. For a much more thorough discussion of how to work with
Tweets as a time series, be sure to read <a class="reference external" href="TODO">this other tutorial</a>.</p>
<p>With this small sample, let&#8217;s do a bit of rough text processing to look
at the text we&#8217;re seeing in these Tweets. A simple - and often,
informative - first way to inspect the content of text data is through
looking at the most common n-grams. In language modeling, an &#8220;n-gram&#8221; is
a contiguous collection of some <em>n</em> items - in languages where
appropriate, this is often white-space separated words. For example,
two-grams in the sentence &#8220;The dog ate my homework&#8221; would be &#8220;the dog&#8221;,
&#8220;dog ate&#8221;, &#8220;ate my&#8221;, &#8220;my homework&#8221;.</p>
<p>We&#8217;ll use the <code class="docutils literal"><span class="pre">all_text</span></code> attribute of our Tweet objects to simply pull
in all the text, regardless of whether it was a Retweet, original Tweet,
or Quote Tweet. Then we&#8217;ll concatenate all the Tweet text together (from
the whole corpus), split it up into words using an open-source tokenizer
from NLTK (we&#8217;ll talk more about this, shortly), remove some
punctuation, and then simply count the most common set of n-grams.</p>
<p>This is a very rough (but quick) way of getting a feel for the text data
we have. If we see content that we don&#8217;t think is relevant, we can go
back and modify our rule.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_all_tokens</span><span class="p">(</span><span class="n">tweet_list</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to generate a list of text tokens from concatenating</span>
<span class="sd">    all of the text contained in Tweets in `tweet_list`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># concat entire corpus</span>
    <span class="n">all_text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">((</span><span class="n">t</span><span class="o">.</span><span class="n">all_text</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">))</span>
    <span class="c1"># tokenize</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">(</span><span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">preserve_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">strip_handles</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
              <span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">all_text</span><span class="p">))</span>
    <span class="c1"># remove symbol-only tokens for now</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">tok</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">tokens</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">get_all_tokens</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of tokens: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">total</span> <span class="n">number</span> <span class="n">of</span> <span class="n">tokens</span><span class="p">:</span> <span class="mi">16160</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># calculate a range of ngrams using some handy functions</span>
<span class="n">top_grams</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">everygrams</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>

<span class="n">top_grams</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[((</span><span class="s1">&#39;sofia&#39;</span><span class="p">,</span> <span class="s1">&#39;coppola&#39;</span><span class="p">),</span> <span class="mi">216</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">),</span> <span class="mi">198</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;at&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">145</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;win&#39;</span><span class="p">),</span> <span class="mi">140</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">),</span> <span class="mi">121</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;cannes&#39;</span><span class="p">,</span> <span class="s1">&#39;film&#39;</span><span class="p">),</span> <span class="mi">117</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">),</span> <span class="mi">116</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">),</span> <span class="mi">116</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;film&#39;</span><span class="p">,</span> <span class="s1">&#39;festival&#39;</span><span class="p">),</span> <span class="mi">109</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">),</span> <span class="mi">107</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;cannes&#39;</span><span class="p">,</span> <span class="s1">&#39;film&#39;</span><span class="p">,</span> <span class="s1">&#39;festival&#39;</span><span class="p">),</span> <span class="mi">106</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">),</span> <span class="mi">105</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">),</span> <span class="mi">104</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">),</span> <span class="mi">104</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;de&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">96</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;cannes&#39;</span><span class="p">,</span> <span class="s1">&#39;2017&#39;</span><span class="p">),</span> <span class="mi">84</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">78</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">),</span> <span class="mi">76</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">),</span> <span class="mi">75</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;en&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">73</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">70</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">70</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;win&#39;</span><span class="p">),</span> <span class="mi">69</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;second&#39;</span><span class="p">),</span> <span class="mi">67</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;festival&#39;</span><span class="p">,</span> <span class="s1">&#39;de&#39;</span><span class="p">),</span> <span class="mi">61</span><span class="p">)]</span>
</pre></div>
</div>
<p>Using these top n-grams, we can see the phrases &#8220;sofia coppola&#8221; and
&#8220;best director&#8221; were very common at the event. If you don&#8217;t happen to be
familiar with the film industry, you may want to inspect those terms a
bit more to understand their context.</p>
<p>We can go back to the Dataframe and filter on one of those terms to see
what the original content was about.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># create a filter series matching &quot;coppola&quot;</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">tweet_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;coppola&quot;</span><span class="p">)</span>

<span class="c1"># look at text only from matching rows</span>
<span class="n">tweet_df</span><span class="p">[</span><span class="n">mask</span><span class="p">][[</span><span class="s1">&#39;text&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>Cannes Film Festival\n‚ÄòThe Square‚Äô Wins Top Prize at @Festival_Cannes\nSofia Coppola ("The Beguiled") Is Best Director\nhttps://t.co/RZilOXxQcV ht...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The last woman to win Best Director at Cannes was Yuliya Solntseva in 1961 for The Story of the Flaming Years. And now Coppola #Cannes2017 https:/...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Congrats to Hillary supporter Sofia Coppola for being only the 2nd woman to win Best Director at the Cannes Film Festival for THE BEGUILED. https:...</td>
    </tr>
    <tr>
      <th>10</th>
      <td>The only female BEST DIRECTOR winners at Cannes in its 70 year history. Both started as actresses: Yuliya Solntseva &amp;amp; Sofia Coppola https://t....</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Coppola/Cannes story is a reminder that if women directors were given equal opportunity more would win. Lots of talented female filmmakers.</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Sofia Coppola becomes the second woman in history to score #Cannes Best Director prize https://t.co/bqiU0ho34o https://t.co/pL73nmHxz4</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Yes @jazzt Let's Celebrate the Best Director @Festival_Cannes #SofiaCoppola for #TheBeguiled We can't wait to see it. \nWOMEN RULE https://t.co/wr...</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Critics are calling Sofia Coppola‚Äôs #TheBeguiled a ‚Äúhilariously fraught feminist psychodrama‚Äù: https://t.co/kM3c5SXiui</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Sofia Coppola is 1st woman to win Best Director at #cannes in 56 years. Jane Campion still only woman to win Palme d'Or. 70 yrs &amp;amp; counting</td>
    </tr>
    <tr>
      <th>46</th>
      <td>https://t.co/U0pNCd2exR #unsigned #talent #forum\n\nCritics are calling Sofia Coppola‚Äôs #TheBeguiled a ‚Äúhilariously‚Ä¶ https://t.co/IlekTpP9Yg</td>
    </tr>
  </tbody>
</table>
</div><p>Ah-ha, it appears Sofia Coppola&#8217;s win as the festival&#8217;s &#8220;Best Director&#8221;
was an historic event (the curious can read about it
<a class="reference external" href="http://www.cnn.com/2017/05/29/entertainment/cannes-sofia-coppola/index.html">here</a>).</p>
<p>These Tweets seem on-topic, and the most common tokens don&#8217;t appear to
have much noise. Since our rule seems to be pretty good, let&#8217;s use it -
unchanged - to collect a bunch more data before we carry on with our
modeling task.</p>
<p>You should be able to run the rest of the analysis below with
<code class="docutils literal"><span class="pre">max_results=20000</span></code> if on a modern laptop with 16 GB of RAM. But if
you run into memory or time constraints, you can always turn down
<code class="docutils literal"><span class="pre">max_results</span></code> and still run the rest of the analysis (or move this
over to a bigger virtual instance if that&#8217;s more your thing).</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tweets</span> <span class="o">=</span> <span class="n">maybe_get_tweets</span><span class="p">(</span><span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;data/larger-cannes.json&quot;</span><span class="p">,</span>
                          <span class="n">rule</span><span class="o">=</span><span class="n">rule</span><span class="p">,</span>
                          <span class="n">max_results</span><span class="o">=</span><span class="mi">20000</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">reading</span> <span class="n">cached</span> <span class="n">tweets</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">50000</span>
</pre></div>
</div>
<p>Let&#8217;s do our quick inspection process again. We&#8217;ll print out our n-grams
and a time-series plot of minute-duration counts.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># ngrams</span>
<span class="n">Counter</span><span class="p">(</span><span class="n">everygrams</span><span class="p">(</span><span class="n">get_all_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[((</span><span class="s1">&#39;cannes&#39;</span><span class="p">,),</span> <span class="mi">32927</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;the&#39;</span><span class="p">,),</span> <span class="mi">27781</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;de&#39;</span><span class="p">,),</span> <span class="mi">16583</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;#cannes2017&#39;</span><span class="p">,),</span> <span class="mi">13598</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;at&#39;</span><span class="p">,),</span> <span class="mi">10778</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;coppola&#39;</span><span class="p">,),</span> <span class="mi">10132</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,),</span> <span class="mi">10023</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;sofia&#39;</span><span class="p">,),</span> <span class="mi">9545</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;square&#39;</span><span class="p">,),</span> <span class="mi">9475</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">),</span> <span class="mi">9453</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;sofia&#39;</span><span class="p">,</span> <span class="s1">&#39;coppola&#39;</span><span class="p">),</span> <span class="mi">9064</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;to&#39;</span><span class="p">,),</span> <span class="mi">9013</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;director&#39;</span><span class="p">,),</span> <span class="mi">9010</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;festival&#39;</span><span class="p">,),</span> <span class="mi">8708</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;la&#39;</span><span class="p">,),</span> <span class="mi">8638</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;in&#39;</span><span class="p">,),</span> <span class="mi">8439</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">),</span> <span class="mi">7731</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;palme&#39;</span><span class="p">,),</span> <span class="mi">7224</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;a&#39;</span><span class="p">,),</span> <span class="mi">7107</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;film&#39;</span><span class="p">,),</span> <span class="mi">6943</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;wins&#39;</span><span class="p">,),</span> <span class="mi">6695</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;en&#39;</span><span class="p">,),</span> <span class="mi">6462</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;at&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">6428</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;win&#39;</span><span class="p">,),</span> <span class="mi">6030</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;du&#39;</span><span class="p">,),</span> <span class="mi">5754</span><span class="p">)]</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># time series</span>
<span class="n">tweet_df</span> <span class="o">=</span> <span class="n">tweets_to_df</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>

<span class="p">(</span><span class="n">tweet_df</span><span class="p">[[</span><span class="s1">&#39;ts&#39;</span><span class="p">,</span><span class="s1">&#39;text&#39;</span><span class="p">]]</span>
 <span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;ts&#39;</span><span class="p">)</span>
 <span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
 <span class="o">.</span><span class="n">count</span><span class="p">()</span>
 <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;minute counts&#39;</span><span class="p">))</span>
 <span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="p">);</span>
</pre></div>
</div>
<img alt="_images/clustering-users_28_0.png" src="_images/clustering-users_28_0.png" />
<p>Now we can see that our first query was way out in the small tail of
data volume (to the right in our chart, toward the chosen end date). Our
query now moves further back into the large-volume region. Even with a
Tweet count limit of many thousands, we&#8217;re still only covering a few
hours of the last day!</p>
<p>Given both the narrow timeframe and Coppola&#8217;s historic win, it&#8217;s
possible that our data collection will be heavily weighted toward that
topic. If we collected all the data back to the beginning of the
festival, we would likely see additional topics surface in our analysis,
and possibly better represent the full breadth of discussion around the
festival.</p>
<p>Nevertheless, we can still move forward with our modeling. Let&#8217;s set the
stage by asking, simply: how many users are we looking at?</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">unique_user_cnt</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">tweet_df</span><span class="p">[</span><span class="s1">&#39;uid&#39;</span><span class="p">]))</span>

<span class="n">unique_user_cnt</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">30819</span>
</pre></div>
</div>
<p>Now that we have a bunch of useful data, let&#8217;s see what kinds of groups
of users we can identify in this collection.</p>
<p>The first thing we&#8217;ll do is a step back to reconsider those rudimentary
processing procedures we just used, and add some sophistication.</p>
</div>
</div>
<div class="section" id="feature-engineering">
<h2>Feature Engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this headline">¬∂</a></h2>
<p>This notebook isn&#8217;t intended to be a general tutorial in feature
engineering or ML model development. But there are some nuances and
choices in how we make the transition from semi-structured (JSON)
Twitter data to the common two-dimensional data matrix of observations
and features that many off-the-shelf machine learning libraries expect.</p>
<p>Domain-specific feature engineering often involves a bit of exploratory
analysis and domain knowledge relevant to the discipline. While we&#8217;re
not going to demonstrate all of that process here, we will instead aim
touch on the main points, and also to point out the steps where the
reader should take time to consider how their own use cases inform
alternative choices.</p>
<div class="section" id="source-data">
<h3>Source data<a class="headerlink" href="#source-data" title="Permalink to this headline">¬∂</a></h3>
<p>First off, we&#8217;ll identify the particular pieces of data from the Tweet
to be used in our model. Recall that the JSON payload from a single
Tweet can have more than 100 key-value pairs.</p>
<p>We&#8217;re going to apply clustering algorithms (a form of unsupervised
learning) to a set of users and some of the text data that represents
them, and there are many ways of consolidating some amount of data to
represent a single user. You could use the users&#8217; most recent (single)
Tweet, their most recent 30-days worth of Tweets (concatenated in one
long string), you could pull out all of the URLs users shared, or the
other users that they mentioned explicitly in their Tweets.</p>
<p>For this example, we&#8217;ll represent each user by the free-form text field
that the user manually enters in their profile to describe themselves,
commonly called the &#8220;user bio&#8221; or the &#8220;bio.&#8221;</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># pick a single random tweet</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">51</span>

<span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">screen_name</span><span class="p">,</span> <span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bio</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="s1">&#39;üéÑSugarPlumFairyüéÑ&#39;</span><span class="p">,</span>
 <span class="s1">&#39;msgoddessrises&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Film/Writer #DivineIntervention #DivineProvidence #independent #MS Saving the world 1 tweet at a time #VegasStrong üôèüèª‚ù§Ô∏èüé≤üóΩüé¢üé°üé∞#GodsInControl. #NeverTrump&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="preprocessing">
<h3>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">¬∂</a></h3>
<p>User-generated text often has quirks and oddities. Even beyond the
design and constraints of a particular user interface, text data can
<a class="reference external" href="https://twitter.com/FakeUnicode">just be difficult</a>. Furthermore,
anytime a platform creates a new phenomena like <code class="docutils literal"><span class="pre">#hashtags</span></code>,
<code class="docutils literal"><span class="pre">&#64;mentions</span></code>, <code class="docutils literal"><span class="pre">$cashtags</span></code>, or the ability to attach media, it
introduces unique patterns of characters into the associated text
fields.</p>
<p>One of the key steps in collecting, processing, and analyzing data from
such a platform is properly accounting for these unique types of data
using the relevant domain knowledge. This collection of tasks is one
that we commonly refer to as <em>preprocessing</em> because it occurs prior to
the data being input to any model.</p>
<p>Choices about how much, and what type, of preprocessing to apply are
subjective. Ideally, you should try to evaluate the effect of varying
choices on the metrics you care about - things like click through rate,
transactions, new customer acquisition, etc. Here, we&#8217;ll demonstrate a
few common examples of preprocessing a user-input text string before it
gets to a model.</p>
</div>
<div class="section" id="handling-urls">
<h3>Handling URLs<a class="headerlink" href="#handling-urls" title="Permalink to this headline">¬∂</a></h3>
<p>A common issue in working with Tweet text is that user-entered URLs will
be run through <a class="reference external" href="https://support.twitter.com/articles/109623">a link
shortener</a>.
Additionally, the user may have <em>also</em> used a link shortener like
<code class="docutils literal"><span class="pre">bit.ly</span></code> for the added analytics. In either case, the literal URL
string we see likely doesn&#8217;t contain much useful information and it will
also lead to an unhelpful excess of low-frequency &#8220;words&#8221; in our
eventual data matrix. Note that while shortened URLs are not
particularly useful (because they&#8217;re typically some form of hash),
&#8220;unrolled URLs&#8221; (i.e. the fully expanded URLS to which the shortened
URLS redirect) can actually provide useful signal e.g. a .org TLD might
signal a business&#8217; website instead of a personal one.</p>
<p>To address this problem, we&#8217;ll strip URLs from the original text with <a class="reference external" href="https://www.bit.ly/PyURLre">a
relatively simple regular expression</a> and
optionally replace them with a new string. It doesn&#8217;t much matter what
string you replace the URLs with, as long as it&#8217;s recognizable in your
later analyses. Note that this regex is reasonable, but definitely not
perfect - if you wanted to make it more robust, you certainly can! For
example, this regex also matches anything that is of the form
<code class="docutils literal"><span class="pre">text.text</span></code> (including email addresses)</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">replace_urls</span><span class="p">(</span><span class="n">in_string</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Replace URLs in strings. See also: ``bit.ly/PyURLre``</span>

<span class="sd">    Args:</span>
<span class="sd">        in_string (str): string to filter</span>
<span class="sd">        replacement (str or None): replacment text. defaults to &#39;&lt;-URL-&gt;&#39;</span>

<span class="sd">    Returns:</span>
<span class="sd">        str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">replacement</span> <span class="o">=</span> <span class="s1">&#39;&lt;-URL-&gt;&#39;</span> <span class="k">if</span> <span class="n">replacement</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">replacement</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;(https?://)?(\w*[.]\w+)+([/?=&amp;]+\w+)*&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">replacement</span><span class="p">,</span> <span class="n">in_string</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># add fake url for demonstration</span>
<span class="n">replace_urls</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bio</span> <span class="o">+</span> <span class="s2">&quot; http://bit.ly/4atsdfzc&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;Film/Writer #DivineIntervention #DivineProvidence #independent #MS Saving the world 1 tweet at a time #VegasStrong üôèüèª‚ù§Ô∏èüé≤üóΩüé¢üé°üé∞#GodsInControl. #NeverTrump &lt;-URL-&gt;&#39;</span>
</pre></div>
</div>
<p>If adding a new term to your data set doesn&#8217;t work for your use case,
you could also replace URLs with a whitespace character. In choosing
your replacement token, be sure to take some time to experiment with the
interaction between it any any downstream processing pieces like
tokenizers.</p>
<p>Other forms of preprocessing include translation from one language to
another, character normalization e.g. unicode to ASCII, or any other
transformation that benefits the context of the full string.</p>
</div>
<div class="section" id="tokenization">
<h3>Tokenization<a class="headerlink" href="#tokenization" title="Permalink to this headline">¬∂</a></h3>
<p>An important step in text processing is splitting the string into tokens
(or words). There are many ways to break up a text string into tokens
(and many text-processing and NLP libraries to assist in doing so). For
the sake of this discussion, we&#8217;re mostly going to look at English. In
that case, splitting text on whitespace is the simplest possible way to
do this. Common text vectorizers - <cite>like those in
``sklearn`</cite> &lt;<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer">http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer</a>&gt;`__
- also have slightly fancier tokenizers already built in for you to use
(we&#8217;ll tal more about vectorization, shortly).</p>
<p>We can also choose to create our own explicit tokenizer if the data (and
task) call for it. One particular method that works with Twitter data is
NLTK&#8217;s
<code class="docutils literal"><span class="pre">`TweetTokenizer</span></code> &lt;<a class="reference external" href="http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.casual.TweetTokenizer">http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.casual.TweetTokenizer</a>&gt;`__.
It does a couple of smart things: preserves <code class="docutils literal"><span class="pre">&#64;</span></code> and <code class="docutils literal"><span class="pre">#</span></code> symbols at
the start of words, and can also &#8220;collapse&#8221; repeated characters - that
is, <code class="docutils literal"><span class="pre">lolll</span></code>, <code class="docutils literal"><span class="pre">lollllll</span></code>, and <code class="docutils literal"><span class="pre">lollllllllllll</span></code> will all collapse to
the same representation <code class="docutils literal"><span class="pre">&quot;lolll&quot;</span></code> (three &#8220;l&#8221;s). This is helpful
because we tend to think that these tokens represent approximately the
same thing. This feature helps curb the curse of dimensionality (i.e.
too many low-frequency tokens), while maintaining Twitter-specific
features.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_tokenizer</span><span class="p">(</span><span class="n">in_string</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert `in_string` of text to a list of tokens using NLTK&#39;s TweetTokenizer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># reasonable, but adjustable tokenizer settings</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">preserve_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">strip_handles</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">in_string</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tokens</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bio</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;Film/Writer #DivineIntervention #DivineProvidence #independent #MS Saving the world 1 tweet at a time #VegasStrong üôèüèª‚ù§Ô∏èüé≤üóΩüé¢üé°üé∞#GodsInControl. #NeverTrump&#39;</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">my_tokenizer</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bio</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;film&#39;</span><span class="p">,</span>
 <span class="s1">&#39;/&#39;</span><span class="p">,</span>
 <span class="s1">&#39;writer&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#divineintervention&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#divineprovidence&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#independent&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#ms&#39;</span><span class="p">,</span>
 <span class="s1">&#39;saving&#39;</span><span class="p">,</span>
 <span class="s1">&#39;the&#39;</span><span class="p">,</span>
 <span class="s1">&#39;world&#39;</span><span class="p">,</span>
 <span class="s1">&#39;1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;tweet&#39;</span><span class="p">,</span>
 <span class="s1">&#39;at&#39;</span><span class="p">,</span>
 <span class="s1">&#39;a&#39;</span><span class="p">,</span>
 <span class="s1">&#39;time&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#vegasstrong&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üôè&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üèª&#39;</span><span class="p">,</span>
 <span class="s1">&#39;‚ù§&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Ô∏è&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üé≤&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üóΩ&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üé¢&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üé°&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üé∞&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#godsincontrol&#39;</span><span class="p">,</span>
 <span class="s1">&#39;.&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#nevertrump&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="remove-stopwords">
<h3>Remove Stopwords<a class="headerlink" href="#remove-stopwords" title="Permalink to this headline">¬∂</a></h3>
<p>Another common processing step involves filtering out words that are
sufficiently common in language that they provide little value. For
example, in English, use of the 1-gram &#8220;the&#8221; is unlikely to provide
valuable signal in a modeling task. Similarly, &#8216;la&#8217; or &#8216;le&#8217; in French.
These words or tokens might actually be useful signal if you&#8217;re trying
to create a text language classifier, but they can also lead us to
overfit a model on low-signal words.</p>
<p>Choosing a domain- and task-relevant list of stopwords is an important
and valuable exercise that does not have a clear-cut, &#8220;correct&#8221; answer.
Many NLP libraries include built-in stopword lists that you can use,
often out-of-the-box e.g. <a class="reference external" href="http://www.nltk.org/nltk_data/">NLTK</a>, and
<a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/stop_words.py">sklearn</a>.
It&#8217;s worth looking into the specific choices that each library makes
with its selection of stopwords to ensure that it aligns with your goals
and expectations for inclusion or removal of content.</p>
<p>Another example that gives the user some fine-grained control over the
words is the <code class="docutils literal"><span class="pre">`python-stop-words</span></code>
library &lt;<a class="reference external" href="https://github.com/Alir3z4/python-stop-words">https://github.com/Alir3z4/python-stop-words</a>&gt;`__. We&#8217;ll use
this library for our demo.</p>
<p>How do we know which languages to add? We can get a good first guess by
counting up the distribution of language classifications in our Tweets.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">Counter</span><span class="p">([</span><span class="n">t</span><span class="o">.</span><span class="n">lang</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">])</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[(</span><span class="s1">&#39;en&#39;</span><span class="p">,</span> <span class="mi">24819</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;fr&#39;</span><span class="p">,</span> <span class="mi">11017</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;es&#39;</span><span class="p">,</span> <span class="mi">6110</span><span class="p">),</span>
 <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1601</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span> <span class="mi">1594</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;de&#39;</span><span class="p">,</span> <span class="mi">1222</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="mi">993</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;tr&#39;</span><span class="p">,</span> <span class="mi">919</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="mi">385</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;sv&#39;</span><span class="p">,</span> <span class="mi">296</span><span class="p">)]</span>
</pre></div>
</div>
<p>It looks like we should consider adding the six or seven languages that
appear in the tall head.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">languages</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;english&#39;</span><span class="p">,</span>
             <span class="s1">&#39;spanish&#39;</span><span class="p">,</span>
             <span class="s1">&#39;portuguese&#39;</span><span class="p">,</span>
             <span class="s1">&#39;german&#39;</span><span class="p">,</span>
             <span class="s1">&#39;french&#39;</span><span class="p">,</span>
             <span class="s1">&#39;italian&#39;</span><span class="p">,</span>
             <span class="s1">&#39;turkish&#39;</span>
            <span class="p">]</span>

<span class="c1"># collect and dedupe</span>
<span class="n">my_stopwords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">((</span><span class="n">get_stop_words</span><span class="p">(</span><span class="n">lang</span><span class="p">)</span>
                                                <span class="k">for</span> <span class="n">lang</span> <span class="ow">in</span> <span class="n">languages</span><span class="p">))))</span>
<span class="nb">len</span><span class="p">(</span><span class="n">my_stopwords</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">1462</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># look at a sample</span>
<span class="n">my_stopwords</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;wir&#39;</span><span class="p">,</span>
 <span class="s1">&#39;estive&#39;</span><span class="p">,</span>
 <span class="s1">&#39;here&#39;</span><span class="p">,</span>
 <span class="s1">&#39;lo&#39;</span><span class="p">,</span>
 <span class="s1">&#39;tendr√≠a&#39;</span><span class="p">,</span>
 <span class="s1">&#39;bon&#39;</span><span class="p">,</span>
 <span class="s1">&#39;tuvimos&#39;</span><span class="p">,</span>
 <span class="s1">&#39;gibi&#39;</span><span class="p">,</span>
 <span class="s1">&#39;los&#39;</span><span class="p">,</span>
 <span class="s1">&#39;tiverem&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Additionally, we can filter out some &#8220;punctuation noise&#8221; from our data
by augmenting the stopword list with some commonly occurring, but
low-value, tokens that comprise punctuation, only. For example, we can
trade &#8220;did you see that?!?%*&amp;&#64;#?!&#8221; for &#8220;did you see that&#8221; without
worrying too much about lost signal.</p>
<p>Since there are many punctuation characters (and it would be slow to
iterate over each character in our tokens to check for all-punctuation
tokens), we&#8217;ll make a simple list of &#8220;words&#8221; that comprise only
punctuation and append them to our current stopword list.</p>
<p>There are a couple of handy built-in features we can use to do this in a
compact way.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># ex: length-2 permutations of the given set of chars</span>
<span class="p">[</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">it</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="s1">&#39;#$.&#39;</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;##&#39;</span><span class="p">,</span> <span class="s1">&#39;#$&#39;</span><span class="p">,</span> <span class="s1">&#39;#.&#39;</span><span class="p">,</span> <span class="s1">&#39;$#&#39;</span><span class="p">,</span> <span class="s1">&#39;$$&#39;</span><span class="p">,</span> <span class="s1">&#39;$.&#39;</span><span class="p">,</span> <span class="s1">&#39;.#&#39;</span><span class="p">,</span> <span class="s1">&#39;.$&#39;</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_punc_stopwords</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates punctuation &#39;words&#39; up to</span>
<span class="sd">    ``max_length`` characters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">punct_maker</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">((</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">it</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">,</span>
                                                <span class="n">repeat</span><span class="o">=</span><span class="n">length</span><span class="p">)))</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">it</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">((</span><span class="n">punct_maker</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">length</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">my_stopwords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="n">my_stopwords</span><span class="p">,</span> <span class="n">make_punc_stopwords</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;current count of stopwords: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">my_stopwords</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;example punctuation words:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">my_stopwords</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]))</span>
</pre></div>
</div>
<pre class="literal-block">
current count of stopwords: 1083863
example punctuation words:
 ['~~~[', '~~~\', '~~~]', '~~~^', '~~~_', '~~~`', '~~~{', '~~~|', '~~~}', '~~~~']
</pre>
<p>At this point, we&#8217;ve added a lot of stopwords! But that should be ok -
most of them were from the punctuation set and should help us focus on
the words that do add signal to the text model. As mentioned before,
it&#8217;s always a good idea to experiment with these choices in your model
development to see if they make sense, or add (or remove!) value from
the metrics you care about.</p>
</div>
<div class="section" id="vectorization">
<h3>Vectorization<a class="headerlink" href="#vectorization" title="Permalink to this headline">¬∂</a></h3>
<p>Most of the available out-of-the-box machine learning algorithms e.g. in
<code class="docutils literal"><span class="pre">sklearn</span></code> expect input in the form of a two-dimensional data matrix of
numerical values: observations (rows) <em>x</em> features (columns). To create
a numerical representation of text data, we need to vectorize the text
features (tokens), and libraries like <code class="docutils literal"><span class="pre">sklearn</span></code> provide many ways to
do this.</p>
<p>For this example, we&#8217;ll use <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer">a
vectorizer</a>
that normalizes the token counts according to the fraction of documents
in which the token appears. That is, it will down-weight tokens that
appear in every document assuming they&#8217;re not special, and vice versa
for infrequent tokens. This particular vectorizer also conveniently
handles the previous preprocessing steps we have outlined. By formatting
our &#8220;remove URLs&#8221; and &#8220;tokenize&#8221; steps as functions, we can simply pass
them into our vectorizer as keyword arguments. Similarly, we can pass in
our custom stopword list for filtering. It&#8217;s worth considering the
interplay between removing stopwords outright (with our
<code class="docutils literal"><span class="pre">my_stopwords</span></code>) and the explicit down-weighting that extremely common
words (like &#8220;the&#8221; and &#8220;les&#8221;) would receive from a TFIDF vectorization.
This is another entry in &#8220;evaluate the effect of the choice for your use
case&#8221; - here, we use both for the increase in computational efficiency
(fewer features).</p>
<p>One common pitfall in feature engineering is generating too many
features for the number of observations. A handy rule-of-thumb from
Google&#8217;s <a class="reference external" href="http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf">Rules of Machine Learning
paper</a> is to
keep the ratio of features to observations at about 1:100. Recall that
we&#8217;re using the literal tokens as features, and we know how many
observations we have based on the earlier unique user count.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">vec</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">replace_urls</span><span class="p">,</span>
                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">my_tokenizer</span><span class="p">,</span>
                      <span class="n">stop_words</span><span class="o">=</span><span class="n">my_stopwords</span><span class="p">,</span>
                      <span class="n">max_features</span><span class="o">=</span><span class="n">unique_user_cnt</span><span class="o">//</span><span class="mi">100</span><span class="p">,</span>
                     <span class="p">)</span>
</pre></div>
</div>
<p>Recall that our &#8220;observations&#8221; are individual users (and their tokenized
bios are our features). Since we collected quite a bit of data, we have
many Tweets by some users. As a result, we must first filter the data
down to one observation per user. While the ordering of our users
doesn&#8217;t matter, we do need to maintain the same ordering between our
user list and the bio list.</p>
<p>The resulting list of unique user bios is our input iterable, and once
we have that we can fit the vectorizer.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># create one entry per user</span>
<span class="n">unique_user_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">t</span><span class="o">.</span><span class="n">user_id</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">bio</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">}</span>

<span class="c1"># we need to maintain the same ordering of users and bios</span>
<span class="n">unique_users</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">unique_bios</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">user</span><span class="p">,</span><span class="n">bio</span> <span class="ow">in</span> <span class="n">unique_user_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">unique_users</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">user</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bio</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># special case for empty bios</span>
        <span class="n">bio</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="n">unique_bios</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bio</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># calculate the data matrix</span>
<span class="n">bio_matrix</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">unique_bios</span><span class="p">)</span>

<span class="n">bio_matrix</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="mi">30819</span><span class="n">x308</span> <span class="n">sparse</span> <span class="n">matrix</span> <span class="n">of</span> <span class="nb">type</span> <span class="s1">&#39;&lt;class &#39;</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="s1">&#39;&gt;&#39;</span>
    <span class="k">with</span> <span class="mi">56373</span> <span class="n">stored</span> <span class="n">elements</span> <span class="ow">in</span> <span class="n">Compressed</span> <span class="n">Sparse</span> <span class="n">Row</span> <span class="nb">format</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Note how sparse the data matrix becomes! This is not only common for
text data, but especially so for Tweet text data. There are lots of
little variations in the way people write things on Twitter that
ultimately leads to a high dimensionality.</p>
<p>To make sure we understand the data matrix, we can reassemble it into a
visual format with a little bit of work. Below, we&#8217;ll display the first
few bios in (close to) their original format, and then the same few bios
as they are represented in the document term matrix (over a narrow slice
of features).</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;* original bio text *</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">bio</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_bios</span><span class="p">[:</span><span class="mi">10</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;: &#39;</span><span class="p">,</span> <span class="n">bio</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span>* original bio text *

0 :  Counselor. Psych Grad. 25 Fangirl. (You&#39;ve been warned) Kristen says I&#39;m rad.Twilight. Kristen. Rob. Jamie Dornan. Tom Sturridge. Nic Hoult. Outlander.
1 :  Veterinario, liberal y cuestionador, debilidad: las mujeres inteligentes con car√°cter fuerte. No a las sumisas.
2 :  love
3 :  Everything happens for a reason,learn from it &amp; move on,don&#39;t be bitter about what happened,be happy about will// Hala Madrid- 1/2ofHMS
4 :  CEO/Founder https://t.co/wY9NweIodu Social media for Opera, Ballet, Symphony goes. Club is Free to join. Special events. Tickets Share..Extraordinary Company!
5 :  ELN - #geopolitics #history #SEO #cin√©ma
6 :
7 :  Follow Zesty #Fashion for the freshest #glamour, #redcarpet, #designer #clothing and #celebrity #beauty news.
8 :  Actress, writer, political junkie and Lake Superior worshipper. Block Bernie, Jill, Nomiki peeps and other mouthy Russians.  #HillaryClintonDem #NeverBernie
9 :  ÏûâÏó¨Îãπ Ïó¥ÏÑ±ÎãπÏõê / Ïû°Îçï / ÏßÑÏßÄÏ∂©
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">todense</span><span class="p">(),</span>
              <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()])</span>
 <span class="c1"># experiment by choosing any range of feature indices (alphabetical order)</span>
 <span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">90</span><span class="p">:</span><span class="mi">110</span><span class="p">])</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>facebook</th>
      <th>family</th>
      <th>fan</th>
      <th>fashion</th>
      <th>feminist</th>
      <th>festival</th>
      <th>film</th>
      <th>filmmaker</th>
      <th>films</th>
      <th>find</th>
      <th>first</th>
      <th>follow</th>
      <th>food</th>
      <th>former</th>
      <th>founder</th>
      <th>france</th>
      <th>free</th>
      <th>freelance</th>
      <th>french</th>
      <th>friends</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.385772</td>
      <td>0.0</td>
      <td>0.39021</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.792739</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div><p>Here, we can clearly see the sparsity of the data matrix.</p>
<p>There are other approaches to text modeling that address the issue of
sparsity like <a class="reference external" href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/">word and document
embeddings</a>.
But, those are outside the scope of this example.</p>
<p>Now we have a representation of our user-text data and we can use this
as an input to our clustering algorithms.</p>
</div>
<div class="section" id="selecting-and-tuning-a-model">
<h3>Selecting and tuning a model<a class="headerlink" href="#selecting-and-tuning-a-model" title="Permalink to this headline">¬∂</a></h3>
<p>There are <a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html">many types of clustering
algorithms</a>
available off-the-shelf through libraries like <code class="docutils literal"><span class="pre">sklearn</span></code>. While we
aren&#8217;t going to work through all of them in this demo, we&#8217;ll compare a
couple different algorithms.</p>
<p><strong>KMeans</strong></p>
<p><a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html#k-means">KMeans</a>
is a common choice because it is very fast for moderate amounts of data.
Like most algorithms, <code class="docutils literal"><span class="pre">KMeans</span></code> has parameters that need to be chosen
appropriately. In this case, that parameter is <code class="docutils literal"><span class="pre">k</span></code>, the number of
clusters in our data.</p>
<p>In unsupervised learning, we can&#8217;t easily calculate (and optimize) an
accuracy score, so we have to use other techniques to compare models to
one another for selecting <code class="docutils literal"><span class="pre">k</span></code>. Since we don&#8217;t know this number <em>a
priori</em>, one technique involves comparing the value of some quality
metric across a range of potential <code class="docutils literal"><span class="pre">k</span></code>s. There are a number of
<a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation">known quality
metrics</a>,
of which we&#8217;ll use just a couple: <a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient">silhouette
score</a>
(larger is better) and inertia (smaller is better).</p>
<p>We typically want to survey a wide, course range of <code class="docutils literal"><span class="pre">k</span></code>s, and then
possibly narrow in to evaluate a smaller range around the best
identified. We&#8217;ll only demonstrate the first step here. This process
takes a lot of processing time, but can be sped up (for k-means, at
least) with more processor cores.</p>
<p>‚ö†Ô∏è <strong>Warning</strong> ‚ö†Ô∏è</p>
<p>The code below may take a few minutes to run on a laptop. If you get
impatient working through this demo, you can either reduce the number of
k values compared to just a couple, or significantly reduce the total
amount of data (<code class="docutils literal"><span class="pre">max_results</span></code> in the query).</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="c1"># compare a broad range of ks to start</span>
<span class="n">ks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>


<span class="c1"># track a couple of metrics</span>
<span class="n">sil_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># fit the models, save the evaluation metrics from each run</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">:</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;fitting model for </span><span class="si">{}</span><span class="s1"> clusters&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">labels_</span>
    <span class="n">sil_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># plot the quality metrics for inspection</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">inertias</span><span class="p">,</span> <span class="s1">&#39;o--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;inertia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;kmeans parameter search&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">sil_scores</span><span class="p">,</span> <span class="s1">&#39;o--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;silhouette score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;k&#39;</span><span class="p">);</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">fitting</span> <span class="n">model</span> <span class="k">for</span> <span class="mi">2</span> <span class="n">clusters</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">fitting</span> <span class="n">model</span> <span class="k">for</span> <span class="mi">50</span> <span class="n">clusters</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">fitting</span> <span class="n">model</span> <span class="k">for</span> <span class="mi">200</span> <span class="n">clusters</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">fitting</span> <span class="n">model</span> <span class="k">for</span> <span class="mi">500</span> <span class="n">clusters</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mi">2</span><span class="nb">min</span> <span class="mi">53</span><span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">1</span><span class="nb">min</span> <span class="mi">56</span><span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mi">4</span><span class="nb">min</span> <span class="mi">50</span><span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mi">6</span><span class="nb">min</span> <span class="mi">23</span><span class="n">s</span>
</pre></div>
</div>
<img alt="_images/clustering-users_63_2.png" src="_images/clustering-users_63_2.png" />
<p>Unfortunately, these metrics will rarely tell you the best answer for
how many clusters are appropriate. Both of these plotted metrics will
asymptotically approach their &#8220;ideal&#8221; value, and so the practitioner is
typically advised to choose the value in <a class="reference external" href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#The_elbow_method">&#8220;the
elbow&#8221;</a>
of these curves - that is, the point at which the returns seem to be
diminishing for an increase in <code class="docutils literal"><span class="pre">k</span></code>.</p>
<p>Based on that pair of figures, it looks like <code class="docutils literal"><span class="pre">k</span> <span class="pre">~</span> <span class="pre">200</span></code> is a good place
to start. To be a bit more careful, we might consider running the same
comparison over a narrower range of <code class="docutils literal"><span class="pre">k</span></code> values between, say, 10 and
500. Furthermore, you&#8217;ll want to consider - and incorporate - other
external constraints on your model. Maybe the number of user clusters
according to the elbow is too many (or too few) to reasonably consider
given the question you&#8217;re trying to answer with the data.</p>
<p>For now, let&#8217;s go with our best k value, train a new model on all of our
data, and carry on with our analysis.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">best_k</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">km_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">best_k</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">km_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">KMeans</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">n_clusters</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">precompute_distances</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="inspecting-model-results">
<h2>Inspecting model results<a class="headerlink" href="#inspecting-model-results" title="Permalink to this headline">¬∂</a></h2>
<p>We now have a trained model of users and the clusters to which they
belong. At this point, we should inspect the resulting clusters to
understand what we&#8217;ve discovered. There are a number of ways to do this
- here we&#8217;ll look at a couple.</p>
<div class="section" id="population-sizes">
<h3>Population sizes<a class="headerlink" href="#population-sizes" title="Permalink to this headline">¬∂</a></h3>
<p>A good first thing to check is simply the population of each cluster.
You can compare these numbers to any prior knowledge you have about the
users, or to identify unexpected results.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))),</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;cluster label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;population sizes with </span><span class="si">{}</span><span class="s1"> clusters&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_k</span><span class="p">));</span>

<span class="c1"># truncate y axis to see the rest better</span>
<span class="c1"># (comment out to see the peak value for the largest cluster)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1000</span><span class="p">);</span>
</pre></div>
</div>
<img alt="_images/clustering-users_67_0.png" src="_images/clustering-users_67_0.png" />
<p>We appear to have one cluster with a very large population, and the rest
with relatively consistent populations. Is that expected? We don&#8217;t have
any particular reason to think that the user clusters would be similarly
sized.</p>
<p>Having one particularly large cluster, however, is a common result.
While it <em>could</em> mean that there are many thousands of very similar
users, it often indicates that we&#8217;re not doing a good job of
differentiating those users - possibly because our data on them is just
not very interesting. While there isn&#8217;t any obvious conclusion at this
point, we&#8217;ll want to consider looking into that particular cluster more
carefully to see what&#8217;s going on there.</p>
</div>
<div class="section" id="cluster-text-association">
<h3>Cluster-text association<a class="headerlink" href="#cluster-text-association" title="Permalink to this headline">¬∂</a></h3>
<p>For another inspection technique, recall that the observations (users)
were clustered in a parameter space comprising the words used in their
bio fields. In the KMeans algorithm, the resulting representation of
these clusters are the coordinates of each cluster&#8217;s centroid in that
token space. Thus, another way to inspect our results is to ask: for
each cluster centroid, which token vectors have the largest projection
onto that centroid? That is, which tokens are most strongly associated
with each cluster?</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">strongest_features</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to display a simple text representation of the top-k most</span>
<span class="sd">    important features in our fit model and vectorizer.</span>

<span class="sd">    model: sklearn model</span>
<span class="sd">    vectorizer: sklearn vectorizer</span>
<span class="sd">    topk: k numbers of words to get per cluster</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># these parts are model-independent</span>
    <span class="n">m_name</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
    <span class="c1"># different calculations per model type</span>
    <span class="k">if</span> <span class="n">m_name</span> <span class="ow">is</span> <span class="s1">&#39;KMeans&#39;</span><span class="p">:</span>
        <span class="n">relevant_labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>
        <span class="n">centroids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">this_label</span> <span class="ow">in</span> <span class="n">relevant_labels</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cluster </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">this_label</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">centroids</span><span class="p">[</span><span class="n">this_label</span><span class="p">,</span> <span class="p">:</span><span class="n">topk</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">ind</span><span class="p">]),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">m_name</span> <span class="ow">is</span> <span class="s1">&#39;HDBSCAN&#39;</span><span class="p">:</span>
        <span class="c1"># ignore noise labels</span>
        <span class="n">relevant_labels</span> <span class="o">=</span> <span class="p">[</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="p">]</span>
        <span class="k">for</span> <span class="n">this_label</span> <span class="ow">in</span> <span class="n">relevant_labels</span><span class="p">:</span>
            <span class="n">matching_rows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">hdbs</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="n">this_label</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">coeff_sums</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">[</span><span class="n">matching_rows</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">A1</span>
            <span class="n">sorted_coeff_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">coeff_sums</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cluster </span><span class="si">{}</span><span class="s1">: &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">this_label</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sorted_coeff_idxs</span><span class="p">[:</span><span class="n">topk</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;This helper method currently only supports KMeans and HDBSCAN models&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">strongest_features</span><span class="p">(</span><span class="n">km_model</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span>Cluster 0: &lt;-url-&gt; good internet insta tweet üåπ snap woman 17 master want may mind god marketing
Cluster 1: &lt;-url-&gt; twitter film director music actress writer like editor art addict fan marketing founder „ÄÇ
Cluster 2: journalist &lt;-url-&gt; freelance film editor views culture producer arts tv writer critic news reporter international
Cluster 3: periodista &lt;-url-&gt; cine editor diario series tv director cultural freelance master journalist social rock instagram
Cluster 4: life love &lt;-url-&gt; every better dream music 4 god trying take beauty 17 mind much
Cluster 5: editor writer &lt;-url-&gt; film news views director magazine freelance critic stories tv cine life books
Cluster 6: ‚Ä¢ like shows heart entertainment wife old tv media pop politics just events content music
Cluster 7: cin√©ma musique s√©ries journaliste &lt;-url-&gt; culture films üé¨ art tv üé• rock fan arts cinema
Cluster 8: journaliste &lt;-url-&gt; culture tweets reporter 4 sports cine üé• internet one instagram art new tv
Cluster 9: c&#39;est vie &lt;-url-&gt; plus culture ‚Äô twitter france cin√©ma ‚ô• content üåà web time digital
Cluster 10: ‚ù§ Ô∏è love &lt;-url-&gt; üíô fan s heart music life live üé¨ just girl üèª
Cluster 11: actor writer director &lt;-url-&gt; producer filmmaker film artist enthusiast insta üé¨ activist travel tv nerd
Cluster 12: mundo noticias &lt;-url-&gt; cine digital diario tv social periodista series twitter personal ‚Äú world rock
Cluster 13: ¬ª ¬´ ‚Äô Ô∏è plus cin√©ma &lt;-url-&gt; c&#39;est vida can day vie musique monde chef
Cluster 14: love &lt;-url-&gt; much way life family music god day sports film Ô∏è movies take books
Cluster 15: ‚ú® üèª &lt;-url-&gt; love life Ô∏è ‚ù§ ‚Äô üåà films see good üé¨ fan student
Cluster 16: ser &lt;-url-&gt; vida cine periodista mundo editor twitter ‚ù§ radio real tv digital noticias perfil
Cluster 17: „ÄÇ „ÄÅ „Éª &lt;-url-&gt; ‚Ä¶ film movie ‚ù§ cinema Ô∏è etc ‚ô° ‚ú® ‚Äç ‚ô•
Cluster 18: can one find &lt;-url-&gt; see better ‚Äô life just things news way love woman want
Cluster 19: ‚Ä¢ &lt;-url-&gt; üá∑ writer director ‚Äô üá∏ Ô∏è üá∫ designer travel student series world actor
Cluster 20: time one life like day good people just great &lt;-url-&gt; every may dream photography podcast
Cluster 21: 18 want 17 &lt;-url-&gt; love films üíô ig university twitter years just books tv estudiante
Cluster 22: üá∑ üá´ üá∫ üá™ üá∏ Ô∏è &lt;-url-&gt; france ‚ù§ french paris üá® ex vie production
Cluster 23: vida cine &lt;-url-&gt; mundo director m√∫sica 5 social noticias diario live digital instagram ‚ù§ twitter
Cluster 24: director film writer &lt;-url-&gt; cine screenwriter founder critic festival views tv producer sports fan us
Cluster 25: cinema film world festival films founder podcast community working critic movie online movies best like
Cluster 26: m√∫sica cine series noticias &lt;-url-&gt; arte tv cultura ¬° mundo pop pol√≠tica bien cultural music
Cluster 27: real &lt;-url-&gt; love noticias life ‚Äô mundo lover twitter ig world international always designer one
Cluster 28: ¬° noticias mundo cine informaci√≥n vida facebook &lt;-url-&gt; m√∫sica 24 web s instagram siempre diario
Cluster 29: just news trying &lt;-url-&gt; twitter guy love want ‚Äô Ô∏è change see mind day anything
Cluster 30: film festival critic &lt;-url-&gt; international production writer director founder lover independent working producer screenwriter freelance
Cluster 31: l&#39;actualit√© &lt;-url-&gt; compte cin√©ma monde site people c&#39;est musique s√©ries twitter vie web films radio
Cluster 32: fan &lt;-url-&gt; musique big music twitter tv sports travel film love guy rock tech writer
Cluster 33: ‚ù§ üíô &lt;-url-&gt; love 2017 music üé• lover series snap fan üé¨ trying heart pop
Cluster 34: france &lt;-url-&gt; ‚Äô culture tweets radio consultant life twitter w lifestyle team marketing cin√©ma good
Cluster 35: 1 &lt;-url-&gt; 2 news tweets Ô∏è 4 new now snap fan rock cin√©ma animal instagram
Cluster 36: noticias &lt;-url-&gt; radio mundo diario global m√∫sica periodista pol√≠tica cin√©filo cuenta cine 2 Ô∏è ‚Ä¶
Cluster 37: amante cine m√∫sica estudiante series director periodista tv vida since 1 amo pol√≠tica always twitter
Cluster 38: cine series tv festival escribo noticias cultural marketing rock mejor ¬° üé¨ üé• magazine informaci√≥n
Cluster 39: writer film &lt;-url-&gt; freelance professional mom health actress founder podcast critic geek nerd love sports
Cluster 40: filmmaker writer &lt;-url-&gt; film screenwriter editor video director journalist big actor new producer critic üé¨
Cluster 41: cin√©filo periodista &lt;-url-&gt; amante comunicaci√≥n cine vida estudiante ser 24 ex series rock actor geek
Cluster 42: och &lt;-url-&gt; journalist film reporter twitter tweets sport s tv culture one editor instagram head
Cluster 43: media news &lt;-url-&gt; cinema film tv marketing tech views digital cultural sport writing social ceo
Cluster 44: 3 2 &lt;-url-&gt; fan 1 4 2017 cinema animal Ô∏è one ig journaliste now twitter
Cluster 45: news &lt;-url-&gt; global world around us breaking latest tweets views see stories games sports s
Cluster 46: new &lt;-url-&gt; city podcast life way film editor music writing every book day journalist stories
Cluster 47: tweets &lt;-url-&gt; personal insta news tweet Ô∏è writing food endorsement founder 5 book fan twitter
Cluster 48: world news around &lt;-url-&gt; better events latest life love dream writer good tv book political
Cluster 49: movie tv music news lover film critic &lt;-url-&gt; book life geek addict screenwriter magazine just
Cluster 50: live life love &lt;-url-&gt; world want music content every tweet just much news food movies
Cluster 51: siempre cine &lt;-url-&gt; üé¨ vida periodista amante noticias estudiante m√∫sica social Ô∏è web mundo lover
Cluster 52: ‚Äô &lt;-url-&gt; s love good üèª ¬´ ¬ª Ô∏è ‚Äù s√©ries writer ‚Äú old üá∑
Cluster 53: cultura arte pop periodista cine &lt;-url-&gt; amante cinema sport blog pol√≠tica digital cultural online noticias
Cluster 54: author &lt;-url-&gt; books editor screenwriter writer journalist film critic director book filmmaker tv political best
Cluster 55: breaking news world &lt;-url-&gt; follow stories around latest top best new rt politics online city
Cluster 56: instagram &lt;-url-&gt; snap love wife screenwriter üá™ cinema twitter fan film life actress magazine day
Cluster 57: üáπ üá∑ üá´ üá® &lt;-url-&gt; üá™ ig Ô∏è üá∏ üá∫ ‚ù§ everything üëª food editor
Cluster 58: cinema &lt;-url-&gt; tv s√©ries music french games books festival community freelance cine independent news lover
Cluster 59: tv film &lt;-url-&gt; watch series news writer shows production critic books nerd music way editor
Cluster 60: √© ser &lt;-url-&gt; mundo vida rt online 4 cinema perfil 3 internet paris cultural ‚ù§
Cluster 61: one &lt;-url-&gt; day us top good news god little love film see life may tweets
Cluster 62: ‚ô• love Ô∏è &lt;-url-&gt; fan life like ex cin√©ma snap ‚Äú 21 art ‚Ä¢ s√©ries
Cluster 63: 20 cine Ô∏è &lt;-url-&gt; old festival ig guy ‚Ä¢ paris films france professional years üá∏
Cluster 64: english tweets french &lt;-url-&gt; tweet journalist student news sport film politics history etc screenwriter twitter
Cluster 65: ig &lt;-url-&gt; snap Ô∏è fan art tweet founder film üé¨ consultant content filmmaker student us
Cluster 66: never &lt;-url-&gt; always like ‚Äô film time love independent make day art life fan people
Cluster 67: girl just tv living nerd french can every better like &lt;-url-&gt; love way world time
Cluster 68: like movies shows tv sometimes us write stuff watch new writer people books critic music
Cluster 69: üèº ‚Äç Ô∏è üèª &lt;-url-&gt; üá™ fan üá∑ ‚ú® üá∫ paris coffee manager 1 üé¨
Cluster 70: news around international sport world global views &lt;-url-&gt; politics sports tech stories entertainment top etc
Cluster 71: communication &lt;-url-&gt; marketing culture consultant web ex sport love manager social views cin√©ma journalist digital
Cluster 72: monde &lt;-url-&gt; cin√©ma plus ‚Äô journaliste tweets france twitter change god rt reporter addict instagram
Cluster 73: ‚Äú ‚Äù ‚Äô &lt;-url-&gt; may can vida passion life one mejor women now god never
Cluster 74: make better life things trying world &lt;-url-&gt; just like movies day follow films write film
Cluster 75: producer director writer film &lt;-url-&gt; tv views editor music actress actor former ceo screenwriter founder
Cluster 76: student film lover &lt;-url-&gt; writer former french arts team actor food 17 photography fashion fan
Cluster 77: business &lt;-url-&gt; news international politics sports world marketing culture tech manager ceo entertainment know consultant
Cluster 78: digital media social content marketing pr music professional film online video photography web writer addict
Cluster 79: vie &lt;-url-&gt; fan paris ex films musique ‚Äô snap production sport opinions real arts geek
Cluster 80: social media manager &lt;-url-&gt; marketing blogger film writer events news life fan internet web cultural
Cluster 81: member &lt;-url-&gt; critic film former lover writer manager make editor director media fan proud author
Cluster 82: „ÄÅ „ÄÇ „Éª ‚Ä¶ ‚ú® &lt;-url-&gt; rock ‚ô° ‚ù§ ‚Ä¢ 20 love producer blog üåπ
Cluster 83: 19 &lt;-url-&gt; Ô∏è ‚Ä¢ ‚ù§ student instagram escribo comunicaci√≥n tech c&#39;est snap black photographer real
Cluster 84: bien vida &lt;-url-&gt; c&#39;est monde fan 5 s√©ries vie 2 ‚Äô mundo noticias escribo city
Cluster 85: account official &lt;-url-&gt; personal news fan twitter tweets top politics new manager just like business
Cluster 86: ‚ô° ‚ù§ life ‚ú® just ‚Ä¢ 5 god heart &lt;-url-&gt; lover üèª sometimes 17 music
Cluster 87: back follow &lt;-url-&gt; go god get head writer now living us make take free best
Cluster 88: s ‚Äô &lt;-url-&gt; let best news tv twitter life one world everything us film little
Cluster 89: informaci√≥n noticias mundo &lt;-url-&gt; diario digital cine twitter series arte real internet global marketing web
Cluster 90: designer &lt;-url-&gt; fashion artist lover writer blogger art author producer activist cinema consultant personal director
Cluster 91: person writer just time good can twitter loves etc ‚Äô editor film live new like
Cluster 92: work &lt;-url-&gt; love views festival make new france living film live time art 2017 pr
Cluster 93: ‚Ä¶ &lt;-url-&gt; vida writer real movies take s now art üá∫ film better etc gusta
Cluster 94: site &lt;-url-&gt; news cinema cin√©ma internet blog vida twitter m√∫sica tv musique film monde now
Cluster 95: star fan &lt;-url-&gt; film movies love enthusiast actor 5 2017 movie author nerd see director
Cluster 96: rt endorsement tweets &lt;-url-&gt; views news politics journalist content music üá™ like fan sometimes things
Cluster 97: amo cine m√∫sica vida periodista &lt;-url-&gt; mejor ‚ù§ cinema √© siempre rock tv üé¨ fan
Cluster 98: ex journaliste culture cin√©ma addict paris &lt;-url-&gt; periodista france rt etc digital radio tv health
Cluster 99: follow news &lt;-url-&gt; back tweets world events like dream may ig podcast just international science
Cluster 100: snapchat instagram &lt;-url-&gt; facebook Ô∏è ig follow üëª ‚ù§ photographer everything actor beauty pop now
Cluster 101: u &lt;-url-&gt; ‚ù§ go 4 w s love way ig ‚ú® 100 life 2 ‚Äç
Cluster 102: cine &lt;-url-&gt; series rock tv m√∫sica movie web twitter internet news digital gusta informaci√≥n god
Cluster 103: latest news world &lt;-url-&gt; find one anything just get entertainment us follow stories around top
Cluster 104: creative director producer film filmmaker &lt;-url-&gt; production lover art arts music digital founder consultant writer
Cluster 105: 21 &lt;-url-&gt; day student radio estudiante french like Ô∏è fan üá∑ films love tv film
Cluster 106: blogger writer &lt;-url-&gt; lover fan activist film music follow love consultant online fashion personal arts
Cluster 107: arte cine cinema &lt;-url-&gt; amante m√∫sica pol√≠tica periodista cultural noticias vida france web 2017 ‚Äô
Cluster 108: info &lt;-url-&gt; news film twitter festival author digital üé• online international games official internet music
Cluster 109: people love &lt;-url-&gt; life like music find tweets film just events way arts art former
Cluster 110: lover music film writer animal &lt;-url-&gt; mom book wife food freelance fan cinema french world
Cluster 111: future writer film lover student cinema art 20 movie photographer views tweets just professional 24
Cluster 112: know everything cinema life anything former film s√©ries musique 2017 sports free first filmmaker films
Cluster 113: chef journaliste culture &lt;-url-&gt; magazine compte cin√©ma politique l&#39;actualit√© tweets france addict founder üé¨ amante
Cluster 114: plus &lt;-url-&gt; ‚Äô web france cin√©ma tweets big sports fan love media vie music site
Cluster 115: Ô∏è &lt;-url-&gt; üé¨ üé• ‚Äç ‚ô• insta üåπ üíô 21 ‚ù§ üèª üèº former fan
Cluster 116: mejor mundo cine informaci√≥n &lt;-url-&gt; ¬° noticias siempre diario m√∫sica web vida bien ig series
Cluster 117: radio &lt;-url-&gt; tv journaliste journalist news periodista internet web producer cin√©ma live 1 editor video
Cluster 118: gusta cine m√∫sica amante &lt;-url-&gt; ser pol√≠tica ‚Ä¶ comunicaci√≥n marketing animal arte vida 100 estudiante
Cluster 119: always love &lt;-url-&gt; things life sometimes music lover writer trying can Ô∏è best ‚ú® anything
Cluster 120: politique culture l&#39;actualit√© musique journaliste sport france &lt;-url-&gt; science ex monde cin√©ma sports s√©ries site
Cluster 121: official twitter account &lt;-url-&gt; film news us magazine festival pr follow entertainment actor tweets latest
Cluster 122: comunicaci√≥n digital marketing social &lt;-url-&gt; cine periodista pol√≠tica mundo estudiante diario web cultura radio vida
Cluster 123: living life writer actress &lt;-url-&gt; actor wife producer instagram now film lover cinema dream best
Cluster 124: web &lt;-url-&gt; noticias cine series periodista tweets ‚Ä¶ views tech etc journaliste tv news editor
Cluster 125: pol√≠tica diario noticias &lt;-url-&gt; cine periodista m√∫sica series cultura vida mundo digital personal 1 global
Cluster 126: proud &lt;-url-&gt; writer lover fan mother mom love music sports human just member geek 4
Cluster 127: üåà ‚Äç Ô∏è ‚ù§ üé• üåπ üá∫ üá™ üé¨ &lt;-url-&gt; üá∏ world trying 17 ‚ú®
Cluster 128: üëª &lt;-url-&gt; snap Ô∏è snapchat instagram üíô ‚ù§ insta ig ‚ô• üá™ üé• paris master
Cluster 129: got just life take one mind everything &lt;-url-&gt; love time want people live can rock
Cluster 130: like just love good want film life change views music may food stories much &lt;-url-&gt;
Cluster 131: movies tv books music shows love watch fan series &lt;-url-&gt; life news games video tweet
Cluster 132: public health &lt;-url-&gt; official communication art journaliste writer global film entertainment head journalist views international
Cluster 133: think just people day now can like always world rock let love guy go rt
Cluster 134: üá® üá∫ üá∑ &lt;-url-&gt; üá™ üá∏ üá´ Ô∏è team artist ‚ú® ‚ù§ rt music filmmaker
Cluster 135: coffee film lover addict music &lt;-url-&gt; writer tv sports books fan good feminist book life
Cluster 136: loves music movies just &lt;-url-&gt; love guy books movie arts film good food girl people
Cluster 137: since &lt;-url-&gt; film fan love community news proud one online 2017 ‚ô° critic time magazine
Cluster 138: entertainment news &lt;-url-&gt; sports politics film music world new tv media lifestyle business best latest
Cluster 139: nature art lover love travel music &lt;-url-&gt; culture science world politics arts addict history books
Cluster 140: facebook &lt;-url-&gt; instagram noticias oficial twitter blog mundo cine arte ig news find fan insta
Cluster 141: go &lt;-url-&gt; get want writer love like ‚Äô filmmaker community make cultural can politics fan
Cluster 142: things &lt;-url-&gt; writer like film sometimes little fan great actor love films fashion news just
Cluster 143: home go &lt;-url-&gt; life mom video animal loves fashion twitter health love lover wife online
Cluster 144: 24 noticias &lt;-url-&gt; news informaci√≥n tv mundo diario online books cuenta series film account want
Cluster 145: born love since s music live living world french &lt;-url-&gt; heart great producer big city
Cluster 146: estudiante cine amante üé• &lt;-url-&gt; arte vida nerd 20 m√∫sica mundo periodista cuenta cultura can
Cluster 147: twitter &lt;-url-&gt; news film latest w lifestyle political much internet cine tv woman international global
Cluster 148: still writer back everything know always living film &lt;-url-&gt; lover producer life girl films every
Cluster 149: first online love actress media free &lt;-url-&gt; like everything founder author just one family movies
Cluster 150: compte twitter &lt;-url-&gt; blog journaliste france musique monde magazine views culture ‚Äô back 2017 free
Cluster 151: blog &lt;-url-&gt; cine movie twitter periodista film tv cinema culture fan news editor podcast journaliste
Cluster 152: nothing know everything just dream good can like ‚ú® politics anything u &lt;-url-&gt; üåπ 20
Cluster 153: free &lt;-url-&gt; online people instagram global god us find world personal writer fashion now lover
Cluster 154: friends 100 family love make music &lt;-url-&gt; life just like best us follow live online
Cluster 155: best news twitter &lt;-url-&gt; film one tv actress food around actor love time way art
Cluster 156: opinions editor film &lt;-url-&gt; news views just personal tweets tv films movies digital writer music
Cluster 157: fashion beauty music &lt;-url-&gt; lifestyle food art love film new magazine pr instagram blogger news
Cluster 158: amante m√∫sica vida &lt;-url-&gt; series master cinema geek web social estudiante s√©ries rock enthusiast digital
Cluster 159: üèª ‚Äç Ô∏è üá™ &lt;-url-&gt; üé• üåà üé¨ insta 1 music always tv ‚Ä¢ ‚ù§
Cluster 160: films books &lt;-url-&gt; independent music love film art tv watch production fan international s√©ries screenwriter
Cluster 161: cuenta personal noticias periodista &lt;-url-&gt; informaci√≥n twitter mundo cine cultura vida cultural rt journalist ‚ú®
Cluster 162: escribo cine periodista &lt;-url-&gt; series arte m√∫sica blog estudiante vida ex ig comunicaci√≥n pol√≠tica tv
Cluster 163: bad good girl like &lt;-url-&gt; life want news never make s√©ries twitter films know 2017
Cluster 164: get &lt;-url-&gt; news us can life just independent things good twitter like one better editor
Cluster 165: feminist writer lover film politics &lt;-url-&gt; geek fan mom activist filmmaker critic writing artist food
Cluster 166: 2 &lt;-url-&gt; 4 ex animal master 5 like fan tv love wife internet periodista us
Cluster 167: manager community &lt;-url-&gt; marketing periodista instagram digital views former production web entertainment social team media
Cluster 168: noticias cine series diario twitter mundo &lt;-url-&gt; tv rt üá∑ director Ô∏è news real 100
Cluster 169: women film rights life films global history community love writer great media art world tv
Cluster 170: oficial cuenta twitter &lt;-url-&gt; diario noticias informaci√≥n mundo cine cultural vida blog facebook 24 m√∫sica
Cluster 171: artist &lt;-url-&gt; writer filmmaker actress activist working director film new ig producer journalist trying ‚ú®
Cluster 172: everything love can just &lt;-url-&gt; god music internet time live fan movies arts people üåπ
Cluster 173: 2017 &lt;-url-&gt; festival france tv film media get day 4 make plus cine animal international
Cluster 174: music love film &lt;-url-&gt; video photography cinema writer city politics life food like news big
Cluster 175: let love know go live one can since us change just take write people great
Cluster 176: enthusiast film writer art &lt;-url-&gt; fan lover tech sports ig music student tv movie entertainment
Cluster 177: culture pop film politics &lt;-url-&gt; arts music news writer tv enthusiast addict critic magazine musique
Cluster 178: human rights activist &lt;-url-&gt; life world politics live art journalist mom international animal lover like
Cluster 179: believe love life want can never person better movies proud little know just music us
Cluster 180: design art creative music &lt;-url-&gt; photography designer director film web new marketing video tech lover
Cluster 181: photographer filmmaker writer director lover &lt;-url-&gt; film media based freelance producer artist art designer student
Cluster 182: now &lt;-url-&gt; get film writer stories time movie tweet just life good around former top
Cluster 183: heart take &lt;-url-&gt; follow art top Ô∏è make writer director life world big real movies
Cluster 184: digital marketing &lt;-url-&gt; diario noticias editor global manager film director photography music mundo consultant founder
Cluster 185: passion film &lt;-url-&gt; life blogger lover things time world stories movies culture arts cin√©ma france
Cluster 186: ‚Ä¢ &lt;-url-&gt; Ô∏è writer music üá∑ 18 üé¨ tv 17 tweets good student lover film
Cluster 187: us follow news &lt;-url-&gt; world tweet facebook politics instagram stories movies reporter best around latest
Cluster 188: art music politics love film photography &lt;-url-&gt; cinema director history writing life food science arts
Cluster 189: perfil &lt;-url-&gt; mundo oficial site informaci√≥n pol√≠tica ser escribo web ‚ù§ twitter online insta radio
Cluster 190: ‡πà ‚ù§ way real 2017 photographer freelance proud everything ‚Ä¢ etc latest day follow &lt;-url-&gt;
Cluster 191: stuff write trying film things make life tv like student &lt;-url-&gt; views love people films
Cluster 192: university film media student writer editor &lt;-url-&gt; cinema director political arts lover science filmmaker feminist
Cluster 193: paris &lt;-url-&gt; france international based culture 1 ‚ú® news writer consultant journaliste ex love editor
Cluster 194: black girl just people 17 &lt;-url-&gt; back author filmmaker film like things screenwriter life writer
Cluster 195: know &lt;-url-&gt; just one like may want get day better things us much guy tweets
Cluster 196: #news &lt;-url-&gt; now love monde site news tweets latest every tv tweet around free live
Cluster 197: online &lt;-url-&gt; news magazine entertainment best cinema video film latest culture much based movies ‚Ä¢
Cluster 198: 100 &lt;-url-&gt; vida radio 1 love digital Ô∏è amante since news back business tech üé•
Cluster 199: mother wife writer woman 2 activist 3 feminist &lt;-url-&gt; ceo girl 2017 lover time good
</pre></div>
</div>
<p>Recall that <code class="docutils literal"><span class="pre">&lt;-URL-&gt;</span></code> is the token for &#8220;there was a URL here&#8221;.</p>
<p>The volume of output here is large, so it&#8217;s pretty challenging to read
and parse - can we really distinguish between any set of these word
lists? This is one of the tricky parts of unsupervised learning - there
isn&#8217;t always a &#8220;best&#8221; choice for selecting these parameters.</p>
<p>For the sake of demonstration, let&#8217;s see what the results look like if
we use the same preprocessing steps but limit the cluster count to a
much smaller number. <strong>Note that this is arbitrary!</strong> Ideally, you will
reflect on how the choice of cluster count is constrained by your use
case, and intended use of the resulting data.</p>
<p>Once we have the trained model, we can look at the same diagnostics.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">smaller_k</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">km_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">smaller_k</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">km_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">KMeans</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">n_clusters</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">precompute_distances</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))),</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;cluster label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;k=</span><span class="si">{}</span><span class="s1"> cluster populations&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">smaller_k</span><span class="p">));</span>

<span class="c1"># truncating the axis again!</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3000</span><span class="p">);</span>
</pre></div>
</div>
<img alt="_images/clustering-users_73_0.png" src="_images/clustering-users_73_0.png" />
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">strongest_features</span><span class="p">(</span><span class="n">km_model</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span>Cluster 0: compte l&#39;actualit√© twitter &lt;-url-&gt; france journaliste musique chef magazine monde ‚Äô blog cin√©ma culture facebook
Cluster 1: &lt;-url-&gt; writer fan ‚Äô like noticias tweets „ÄÇ music vida social media director lover tv
Cluster 2: twitter official &lt;-url-&gt; oficial account news best film cuenta ‚Äô us facebook noticias fan blog
Cluster 3: &lt;-url-&gt; facebook noticias perfil writer editor ‚Ä¶ blog info site periodista director tweets news ig
Cluster 4: ‚Ä¢ &lt;-url-&gt; Ô∏è üá∑ student writer ig üé¨ tv üá´ 18 music good filmmaker film
Cluster 5: mundo noticias &lt;-url-&gt; informaci√≥n mejor cine digital ¬° perfil diario twitter oficial periodista cultura 24
Cluster 6: heart take &lt;-url-&gt; Ô∏è ‚ù§ follow life make art top writer born everything director lover
Cluster 7: plus c&#39;est &lt;-url-&gt; cin√©ma monde ‚Äô site web news sports ¬´ ¬ª arts france films
Cluster 8: film critic tv festival writer &lt;-url-&gt; director producer music lover student media editor production enthusiast
Cluster 9: news latest breaking &lt;-url-&gt; entertainment follow us politics get media around stories tv sports best
Cluster 10: cinema &lt;-url-&gt; tv music film lover art arte s√©ries french love site books student media
Cluster 11: just girl &lt;-url-&gt; like anything news one life trying find ‚Äô guy know latest love
Cluster 12: instagram &lt;-url-&gt; snapchat facebook fashion follow film director photographer culture snap fan love beauty time
Cluster 13: love music &lt;-url-&gt; live movies like always art films people family everything film much god
Cluster 14: journaliste ex &lt;-url-&gt; chef culture cin√©ma radio tweets politique france paris tv web s√©ries sport
Cluster 15: artist &lt;-url-&gt; writer director filmmaker designer art producer lover film activist photographer actor music actress
Cluster 16: life love live living &lt;-url-&gt; good music one make movies like better lover real art
Cluster 17: Ô∏è ‚ù§ ‚Äç üåà &lt;-url-&gt; üèª üé• üé¨ üèº love üá∑ üíô ‚ô• fan üá´
Cluster 18: cine m√∫sica series &lt;-url-&gt; periodista escribo amante arte gusta noticias blog director tv vida cultura
Cluster 19: world news around &lt;-url-&gt; latest music love better us breaking entertainment change events follow live
</pre></div>
</div>
<p>Here, we can see some distinctions in the first (strongest) terms: news,
cine, student, etc., as well as some apparently language-based, and
emoji-heavy clusters.</p>
<p>Since this particular view of tokens is centroid-specific, we&#8217;ve lost
the context of the original text. We can also invert the query and look
at a sample of original-text bios that were assigned to a particular
cluster.</p>
<p>Let&#8217;s look at the full texts from a cluster that seems interesting. You
can choose any of the cluster numbers from the output above.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cluster_sample</span><span class="p">(</span><span class="n">orig_text</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">preview</span><span class="o">=</span><span class="mi">15</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to display original bio for</span>
<span class="sd">    those users modeled in cluster `idx`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="n">idx</span><span class="p">)[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">orig_text</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">preview</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;( &gt;&gt;&gt; truncated preview &lt;&lt;&lt; )&#39;</span><span class="p">)</span>
            <span class="k">break</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># feel free to modify this</span>
<span class="n">interest_idx</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">cluster_sample</span><span class="p">(</span><span class="n">unique_bios</span><span class="p">,</span> <span class="n">km_model</span><span class="p">,</span> <span class="n">interest_idx</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span>Autenticamente, sin recetas por naturaleza ,trotamundos por Hobby , construyendo un mundo mejor!!!! 120%positivismo, hija,hermana,amiga de nacimiento

Menos follow, m√°s noticias. Toda la informaci√≥n de argentina y el mundo en una sola cuenta.

Te ofrecemos un panorama completo del acontecer en M√©xico üá≤üáΩ y el mundo.             Participa con nosotros #OnceNoticias

Periodista. Ayer RPP. Hoy Latina. Colecciono autos, pero solo de escala. Real Madrid, Joaqu√≠n Sabina, cine, cr√≥nicas: mi mundo. So√±ando con cubrir unos JJ. OO.

¬°Ciudadano de un lugar llamado mundo!

¬øPara qu√© se lee literatura sino para cuestionar, dialogar y enriquecer el mundo propio?    #NiUnaMenos

√öltimas not√≠cias do Brasil e do Mundo!

BOT de Noticias de Chile.  Recopilaci√≥n instant√°nea de noticias de Chile y el mundo. Informaci√≥n sobre internet, tecnolog√≠a y econom√≠a.

La Frikoteka es un sitio web dedicado a hablar de cine y todo lo relacionado con el mundo Friki.

Noticias de Tierra del Fuego, Argentina y el mundo contacto@noticiastdf.com.ar  telegram https://t.me/noticiastdf

Encuentra lo que no te dicen otros medios en teleSUR. Con m√°s de 40 corresponsales en el mundo te acercamos a la noticia.Somos la se√±al Informativa desde el Sur

Proyectamos noticias de todo el mundo del #cine desde #Valladolid .No somos la cuenta oficial

Que cada um de n√≥s fa√ßa a sua parte para que se d√™ um novo reencantamento do mundo,a come√ßar por nosso mundo interior.  (Mia Couto)

Periodista y Declamador de Poemas. ¬°#SIGUEMEYTESIGO! El periodismo es el mejor oficio del mundo: Gabriel Garc√≠a M√°rquez. üá®üá¥https://t.co/fJXrAb96MK üôèüëçüì∞

ahoradigital es un portal de noticias que monitorea, selecciona y produce informaci√≥n mas importante de Bolivia y el mundo

Las √∫ltimas noticias de Latinoam√©rica y del mundo. Todo el tiempo. https://app.infobae.com/#america

Revista online de moda, cultura y arte en Lima y el mundo

( &gt;&gt;&gt; truncated preview &lt;&lt;&lt; )
</pre></div>
</div>
<p>Based on this sample of user bios, it does look like we&#8217;ve identified a
group of users who self-identify quite similarly. Importantly, however,
note the range of other qualities that are also represented - sometimes
they span politics, media, and geography.</p>
<p>If you were interested in looking at additional bio patterns <em>within</em>
that cluster, you could use these modeled labels as a filter and
calculate a similar rough n-gram list as we did earlier for Tweet text.</p>
<p>In addition to using the clusters to identify relevant groups of users,
you could also decide that a cluster represents a source of noise to be
filtered out in the rest of your analysis. For example, perhaps you want
to filter out users who seem to self-describe in a particular language
or from a particular country.</p>
<p>Furthermore, you could apply more advanced forms of topic modeling to
these groups - we&#8217;ve only mentioned the simplest form: n-gram counting.</p>
</div>
<div class="section" id="visualization">
<h3>Visualization<a class="headerlink" href="#visualization" title="Permalink to this headline">¬∂</a></h3>
<p>Finally, we might want to look at a graphical representation of our
results somehow to get another check on what we discovered. Typically in
text-based models, the dimensionality of the feature space is too high
for direct visualization techniques. While we cannot simply plot all the
users in the token space and color them by their clusters, we can do
something similar if we apply some dimensionality reduction.</p>
<p>One popular approach for doing this is to use
<a class="reference external" href="http://scikit-learn.org/stable/modules/manifold.html#t-sne">t-SNE</a>
to create a 2- or 3-dimensional view of the data. t-SNE attempts to
maintain - in the lower-dimensional representation - some of the
relative structure present in the original, high-dimensionality data.
Note that this technique is helpful for visualization but would be a
problematic step for the middle of a data processing pipeline e.g. prior
to clustering (<a class="reference external" href="https://distill.pub/2016/misread-tsne/">t-SNE is a non-deterministic
algorithm</a>, so you&#8217;ll lose
any reproducibility).</p>
<p>The <code class="docutils literal"><span class="pre">sklearn</span></code> implementation of t-SNE is still somewhat slow, and the
one used here (<code class="docutils literal"><span class="pre">MulticoreTSNE</span></code>) can be <a class="reference external" href="https://github.com/DmitryUlyanov/Multicore-TSNE#benchmark">quite a bit
faster</a>.
For the size of data we have here, it will still take around ten minutes
to fit this reduction on a laptop.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">maybe_fit_tsne</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">file</span> <span class="o">=</span> <span class="s2">&quot;data/bio_matrix_2d.npy&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">bio_matrix_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;loading cached TSNE file&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Fitting TSNE&quot;</span><span class="p">)</span>
        <span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">bio_matrix_2d</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">bio_matrix</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>

        <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">bio_matrix_2d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bio_matrix_2d</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tsne_file</span> <span class="o">=</span> <span class="s2">&quot;data/bio_matrix_2d.npy&quot;</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">bio_matrix_2d</span> <span class="o">=</span> <span class="n">maybe_fit_tsne</span><span class="p">(</span><span class="n">tsne_file</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">loading</span> <span class="n">cached</span> <span class="n">TSNE</span> <span class="n">file</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">2.1</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mf">2.49</span> <span class="n">ms</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">4.59</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">3.76</span> <span class="n">ms</span>
</pre></div>
</div>
<p>In two dimensions, we can plot the data. Even better, we can add
additional visual cues to inform our data inspection like coloring
according to cluster labels, and adding the original text content for
interactive exploration. For this, we can use some of the handy
functionality of the bokeh plotting library. For more context on the
options within that library, <a class="reference external" href="https://bokeh.pydata.org/en/latest/">refer to the
documentation</a>.</p>
<p>The one extra step we have to take, however, is coercing our various
pieces of data into a dataframe that plays nice with the library.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_plottable_df</span><span class="p">(</span><span class="n">users</span><span class="p">,</span> <span class="n">bios</span><span class="p">,</span> <span class="n">two_d_coords</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Combine the necessary pieces of data to create a data structure that plays</span>
<span class="sd">    nicely with the our 2d tsne chart.</span>

<span class="sd">    Note: assumes that all argument data series</span>
<span class="sd">    are in the same order e.g. the first user, bio, coords, and label</span>
<span class="sd">    all correspond to the same user.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># set up color palette</span>
    <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s1">&#39;hls&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
    <span class="n">color_lookup</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))}</span>
    <span class="c1"># combine data into a single df</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;uid&#39;</span><span class="p">:</span> <span class="n">users</span><span class="p">,</span>
                       <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">bios</span><span class="p">,</span>
                       <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span>
                       <span class="s1">&#39;x_val&#39;</span><span class="p">:</span> <span class="n">two_d_coords</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                       <span class="s1">&#39;y_val&#39;</span><span class="p">:</span> <span class="n">two_d_coords</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
                      <span class="p">})</span>
    <span class="c1"># convert labels to colors</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">color_lookup</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">labels</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">df</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># pass in the cluster assignments from the kmeans model</span>
<span class="n">km_plottable_bios</span> <span class="o">=</span> <span class="n">get_plottable_df</span><span class="p">(</span><span class="n">unique_users</span><span class="p">,</span> <span class="n">unique_bios</span><span class="p">,</span> <span class="n">bio_matrix_2d</span><span class="p">,</span> <span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>

<span class="n">km_plottable_bios</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>text</th>
      <th>uid</th>
      <th>x_val</th>
      <th>y_val</th>
      <th>color</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>Counselor. Psych Grad. 25 Fangirl. (You've been warned) Kristen says I'm rad.Twilight. Kristen. Rob. Jamie Dornan. Tom Sturridge. Nic Hoult. Outla...</td>
      <td>711474468</td>
      <td>-7.013775</td>
      <td>16.495875</td>
      <td>#dbd657</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Veterinario, liberal y cuestionador, debilidad: las mujeres inteligentes con car√°cter fuerte. No a las sumisas.</td>
      <td>153826105</td>
      <td>18.301535</td>
      <td>-18.200876</td>
      <td>#db8657</td>
    </tr>
    <tr>
      <th>2</th>
      <td>13</td>
      <td>love</td>
      <td>3179550766</td>
      <td>-23.350645</td>
      <td>-2.489925</td>
      <td>#575cdb</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>Everything happens for a reason,learn from it &amp; move on,don't be bitter about what happened,be happy about will// Hala Madrid- 1/2ofHMS</td>
      <td>314300800</td>
      <td>-13.057721</td>
      <td>-14.508081</td>
      <td>#db8657</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>CEO/Founder https://t.co/wY9NweIodu Social media for Opera, Ballet, Symphony goes. Club is Free to join. Special events. Tickets Share..Extraordin...</td>
      <td>713888098313224192</td>
      <td>27.424238</td>
      <td>6.797698</td>
      <td>#dbd657</td>
    </tr>
  </tbody>
</table>
</div><div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_tsne</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;t-SNE plot&#39;</span><span class="p">):</span>
    <span class="c1"># add our DataFrame as a ColumnDataSource for Bokeh</span>
    <span class="n">plot_data</span> <span class="o">=</span> <span class="n">ColumnDataSource</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="c1"># configure the chart</span>
    <span class="n">tsne_plot</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> <span class="n">plot_width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">plot_height</span><span class="o">=</span><span class="mi">700</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;pan, box_zoom, reset&#39;</span><span class="p">))</span>
    <span class="c1"># add a hover tool to display words on roll-over</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">add_tools</span><span class="p">(</span>
        <span class="n">HoverTool</span><span class="p">(</span><span class="n">tooltips</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;&lt;div style=&quot;width: 400px;&quot;&gt;(@label) @text&lt;/div&gt;&quot;&quot;&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># draw the words as circles on the plot</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">circle</span><span class="p">(</span><span class="s1">&#39;x_val&#39;</span><span class="p">,</span> <span class="s1">&#39;y_val&#39;</span><span class="p">,</span>
                     <span class="n">source</span><span class="o">=</span><span class="n">plot_data</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s1">&#39;color&#39;</span><span class="p">,</span>
                     <span class="n">line_alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                     <span class="n">fill_alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                     <span class="n">hover_line_color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="c1"># configure visual elements of the plot</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">text_font_size</span> <span class="o">=</span> <span class="s1">&#39;12pt&#39;</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">visible</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">visible</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">grid</span><span class="o">.</span><span class="n">grid_line_color</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">outline_line_color</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">tsne_plot</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">show</span><span class="p">(</span><span class="n">plot_tsne</span><span class="p">(</span><span class="n">km_plottable_bios</span><span class="p">,</span> <span class="s1">&#39;t-sne projection of kmeans-clustered users [&quot;(cluster #) bio&quot;]&#39;</span><span class="p">))</span>
</pre></div>
</div>
<iframe src="_static/kmeans_bokeh.html" height="750x" width="90%"></iframe><div class="bk-root">
    <div class="bk-plotdiv" id="ebe12f3d-35b5-4837-ab89-e44250cb3271"></div>
</div><p>We can use the mouseover text to explore the color-coded clusters. The
current configuration of the mouseover text is &#8220;(<code class="docutils literal"><span class="pre">&lt;cluster</span> <span class="pre">number&gt;</span></code>)
<code class="docutils literal"><span class="pre">&lt;bio</span> <span class="pre">text&gt;</span></code>&#8221;. Some of the text patterns that I observed in the
clusters above:</p>
<ul class="simple">
<li>broad, language-based clusters (Spanish, French, etc.)</li>
<li>&#8220;breaking news&#8221; and news account clusters (in multiple languages)</li>
<li>emoji-heavy clusters, including one that seems tightly clustered
around the ‚ù§Ô∏è (&#8220;red heart&#8221;) character</li>
<li>other clusters that seem weighted on a varying sets of specific
unicode characters</li>
<li>&#8220;actor&#8221; and &#8220;director&#8221; clusters</li>
<li>the really large, amorphous cluster without an obvious pattern</li>
</ul>
<p>So, what can we learn from this view?</p>
<p>First off, the last cluster mentioned (the large, indistinct cluster)
appears to comprise - among other things - a mix of empty bios (blank
strings) and low-frequency words that weren&#8217;t important in the model.
This is often the case when dealing with user-generated text. More data
(more observed users) might mitigate this risk by contributing more
signal to those words, but there is no guarantee.</p>
<p>Second, handling unicode characters (possibly multi-byte ones) is
important! Recall that we stripped most of the punctuation-only tokens
from our data before fitting a model - now we can see that we only did
so for ASCII punctuation. Depending on your model goals, it might be
useful to also specify a range of higher-value unicode characters to add
as stopwords. Or, alternatively, handle characters like emoji in a
special preprocessing step.</p>
<p>Perhaps at this point you&#8217;ve decided this model is good enough for your
use case and you set out to learn more about the clusters of interest -
maybe for an outreach campaign, or to better understand who&#8217;s paying
attention to the events at the Cannes Film Festival.</p>
<p>Alternatively, perhaps you&#8217;re skeptical, or just not satisfied with the
results of this effort and you&#8217;d like to try another type of model. Next
up, we&#8217;ll do a quick iteration with a different type of model.</p>
</div>
</div>
<div class="section" id="model-iteration">
<h2>Model iteration<a class="headerlink" href="#model-iteration" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="hdbscan">
<h3>HDBSCAN<a class="headerlink" href="#hdbscan" title="Permalink to this headline">¬∂</a></h3>
<p>While fast and simple, <code class="docutils literal"><span class="pre">KMeans</span></code> is not the ideal model for text-based
clustering. There are a number of reasons why you might choose a
different algorithm - most of which boil down to <a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html">bad assumptions made
of the input
data</a>.</p>
<p>Let&#8217;s consider how we would proceed with another type of clustering
model. <code class="docutils literal"><span class="pre">HDBSCAN</span></code> is a hierarchical model that also allows observations
to be classified as noise. These are just two of many handy features,
many more of which are described in the <code class="docutils literal"><span class="pre">`HDBSCAN</span></code>
docs &lt;<a class="reference external" href="https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html">https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html</a>&gt;`__.</p>
<p>One of the convenient features of HDBSCAN is that the main user-chosen
parameter is effectively &#8220;what is the minimum number of observations you
would consider a &#8216;cluster&#8217;?&#8221;. Again, this is a parameter that you have
to select based on knowledge of your specific problem and constraints.
One related, and particularly useful, feature of HDBSCAN is that
clusters of points below this threshold will be labeled as &#8220;noise&#8221;
instead of being assigned to a cluster. For now, let&#8217;s assume that once
we have 100 people that are pretty similar, that&#8217;s officially a real
cluster.</p>
<p>After fitting this new model, we&#8217;ll quickly run through the same
inspection techniques we used earlier. Note that this model takes longer
to fit than the KMeans model - expect a few minutes - and will cache
some of the calculations in the <code class="docutils literal"><span class="pre">data/</span></code> location for faster use later.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">maybe_fit_hdbscan</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;data/hdbscan.pkl&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">hdbs</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;loading cached HDBSCAN model&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;fitting HDBSCAN model&quot;</span><span class="p">)</span>
        <span class="n">hdbs</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_cluster_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                               <span class="n">prediction_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">core_dist_n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                               <span class="n">memory</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
        <span class="n">hdbs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bio_matrix</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>
        <span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">hdbs</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">hdbs</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">hdbscan_file</span> <span class="o">=</span> <span class="s1">&#39;data/hdbscan.pkl&#39;</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">hdbs</span> <span class="o">=</span> <span class="n">maybe_fit_hdbscan</span><span class="p">(</span><span class="n">hdbscan_file</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">loading</span> <span class="n">cached</span> <span class="n">HDBSCAN</span> <span class="n">model</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mi">108</span> <span class="n">ms</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">265</span> <span class="n">ms</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mi">373</span> <span class="n">ms</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mi">518</span> <span class="n">ms</span>
</pre></div>
</div>
</div>
<div class="section" id="populations-sizes">
<h3>Populations sizes<a class="headerlink" href="#populations-sizes" title="Permalink to this headline">¬∂</a></h3>
<p>Because of the differences in the models, we have to extract some of the
features slightly differently. Note, as well, that with HDBSCAN we don&#8217;t
specify the number of clusters <em>a priori</em> - we can see how many were
found once it&#8217;s fit, though.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># get the population sizes</span>
<span class="n">label_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">hdbs</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">label_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="c1"># draw the chart</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_counts</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;cluster label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;population sizes (</span><span class="si">{}</span><span class="s1"> clusters found by hdbscan)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_counts</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">));</span>
</pre></div>
</div>
<img alt="_images/clustering-users_94_0.png" src="_images/clustering-users_94_0.png" />
<p>Recall that in the <a class="reference external" href="https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html">HDBSCAN cluster
assignments</a>,
the &#8220;noise&#8221; points (which don&#8217;t belong in any cluster) are all given a
cluster of <code class="docutils literal"><span class="pre">-1</span></code>. Following this model fit, we can see that a
significant number of the users were not assigned to a real cluster -
they were instead labeled as noise.</p>
</div>
<div class="section" id="id1">
<h3>Cluster-text association<a class="headerlink" href="#id1" title="Permalink to this headline">¬∂</a></h3>
<p>Similarly to how we looked at the words that were most strongly
associated with KMeans clusters, we can also inspect the features most
central in our HDBSCAN clusters. The calculation is a bit different, but
the idea is still the same.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">strongest_features</span><span class="p">(</span><span class="n">hdbs</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span>Cluster 0: &lt;-url-&gt; film writer music tv lover news world producer movies culture love art life perfil
Cluster 1: &lt;-url-&gt; film blogger writer politics music passion director us now freelance life news designer social
Cluster 2: &lt;-url-&gt; news music writer film lover art entertainment tv love life enthusiast director media one
Cluster 3: &lt;-url-&gt; music women film writer news cultural books entertainment comunicaci√≥n since good can arts top
Cluster 4: &lt;-url-&gt; film tv music writer news movies love world art media movie life director people
Cluster 5: &lt;-url-&gt; music film news food media life founder art beauty writer get author cultural live
Cluster 6: &lt;-url-&gt; film news writer friends author media love get new music art tv films movies
Cluster 7: üíô founder filmmaker films find first follow food former france girl free freelance french friends
Cluster 8: ‚Äô s &lt;-url-&gt; ¬´ ¬ª ig believe good plus time back 5 2 Ô∏è founder
Cluster 9: fan cinema instagram tweets cine üíô films find first follow food former founder france free
Cluster 10: „ÄÇ „ÄÅ &lt;-url-&gt; „Éª ‚Ä¶ radio movie film cin√©ma ‚ô° communication science music may Ô∏è
Cluster 11: noticias &lt;-url-&gt; mundo rt real tv cultura üíô follow films find first food film former
Cluster 12: ‚Ä¢ &lt;-url-&gt; writer music Ô∏è tv love art s film editor 1 actor travel üåà
Cluster 13: &lt;-url-&gt; film twitter like can periodista instagram facebook business cine web radio music siempre just
Cluster 14: news &lt;-url-&gt; 24 sport films find first follow food former founder film france free freelance
</pre></div>
</div>
<p>Among other things, this time we observe that all of the identified
clusters frequently have a URL replacement in the text.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># feel free to modify this</span>
<span class="n">interest_idx</span> <span class="o">=</span> <span class="mi">6</span>

<span class="n">cluster_sample</span><span class="p">(</span><span class="n">unique_bios</span><span class="p">,</span> <span class="n">hdbs</span><span class="p">,</span> <span class="n">interest_idx</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span>More than 90% of businesses start with an online search to find a vendor. Then phone calls, voicemails and emails that get nowhere. Had enough? Then try Qahootz

actress wannabe‚Ñ¢  milf enthusiast‚Ñ¢

Former co-founder and Content Director at Rolling Stone&#39;s video game channel, Glixel. Previously at 1UP, EDGE, Wikia/Fandom. All views strictly my own.

#BiPolar #lib #willNEVER4give #GOP 4 @realDonaldTrump üåùüåîüåìüåíüòº ‚ù§Ô∏è#cspanwj/~/~/ &#39;You might very well think so but I couldn&#39;t possibly comment&#39; Pls be kind....

.. a Geek by Nature.

A community for the superwomen who run the entrepreneurial world.

Director &amp; Producer | Creative Consultant | Film Lecturer @SAEInstituteAUS | Father of 2 girls | Owner of 2 cats | I like action movies with subtext.

Nobody exists on purpose, nobody belongs anywhere, everybody&#39;s going to die, come watch tv

AOL Entertainment is the ultimate destination for everything celebrity news, style, fashion and more on http://AOL.com .

Directeur de production, op√©rateur drone chez http://www.airnzoom.com cin√© tv  bas√© sur Montpellier,

Comunicaci√≥n &amp; Big Data

Nollywood Actor/Filmmaker/Blogger/Show Biz Wonder

The best source on the internet for all the latest news, rumors and gossip on Academy Award-winning actress Nicole Kidman. #TheBeguiled #notnicole

If you feel like the world has been taken away from you, figure out how to take it back - don&#39;t just shout about it!  Rob Cannes 2012

No day shall erase you from the memory of the time.   When you persevere the enemy is silenced by your strength.

Slytherin from head to soul. I&#39;m always hungry and oversensitive, so don&#39;t talk nonsense. INTP. My obssession: Park Shin Yang, Jeremy Renner and Joaquin Phoenix

Entrepreneur in the World of arts and antques http://iartdealer.biz 5 square meter Art Gallery free lance journalis Real Estate Project Toy Museum

( &gt;&gt;&gt; truncated preview &lt;&lt;&lt; )
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h3>Visualization<a class="headerlink" href="#id2" title="Permalink to this headline">¬∂</a></h3>
<p>We can also use a similar visualization template to inspect our results
in graphical form. We&#8217;ll use the <code class="docutils literal"><span class="pre">get_plottable_df()</span></code> helper function
again, along with the same list of users, bios, and even the same
two-dimensional reduction of the data matrix. As a result, the x and y
positions of the users should remain the same (remember that the t-SNE
model was based on the vectorized text data matrix, not any particular
clustering of it), but we&#8217;ll pass in the user cluster labels (used for
chart colors) generated by our HDBSCAN model this time.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># pass in the cluster assignments from the hdbscan model</span>
<span class="n">hdb_plottable_bios</span> <span class="o">=</span> <span class="n">get_plottable_df</span><span class="p">(</span><span class="n">unique_users</span><span class="p">,</span> <span class="n">unique_bios</span><span class="p">,</span> <span class="n">bio_matrix_2d</span><span class="p">,</span> <span class="n">hdbs</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>

<span class="n">hdb_plottable_bios</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>text</th>
      <th>uid</th>
      <th>x_val</th>
      <th>y_val</th>
      <th>color</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>13</td>
      <td>Counselor. Psych Grad. 25 Fangirl. (You've been warned) Kristen says I'm rad.Twilight. Kristen. Rob. Jamie Dornan. Tom Sturridge. Nic Hoult. Outla...</td>
      <td>711474468</td>
      <td>-7.013775</td>
      <td>16.495875</td>
      <td>#d357db</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7</td>
      <td>Veterinario, liberal y cuestionador, debilidad: las mujeres inteligentes con car√°cter fuerte. No a las sumisas.</td>
      <td>153826105</td>
      <td>18.301535</td>
      <td>-18.200876</td>
      <td>#57dbb2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1</td>
      <td>love</td>
      <td>3179550766</td>
      <td>-23.350645</td>
      <td>-2.489925</td>
      <td>#db5780</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1</td>
      <td>Everything happens for a reason,learn from it &amp; move on,don't be bitter about what happened,be happy about will// Hala Madrid- 1/2ofHMS</td>
      <td>314300800</td>
      <td>-13.057721</td>
      <td>-14.508081</td>
      <td>#db5780</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1</td>
      <td>CEO/Founder https://t.co/wY9NweIodu Social media for Opera, Ballet, Symphony goes. Club is Free to join. Special events. Tickets Share..Extraordin...</td>
      <td>713888098313224192</td>
      <td>27.424238</td>
      <td>6.797698</td>
      <td>#db5780</td>
    </tr>
  </tbody>
</table>
</div><div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">show</span><span class="p">(</span><span class="n">plot_tsne</span><span class="p">(</span><span class="n">hdb_plottable_bios</span><span class="p">,</span> <span class="s1">&#39;t-sne projection of hdbscan-clustered users [&quot;(cluster #) bio&quot;]&#39;</span><span class="p">))</span>
</pre></div>
</div>
<iframe src="_static/hdbscan_bokeh.html" height="750x" width="90%"></iframe><p>The specific color-cluster pairs have no meaning (i.e. a blue-ish group
in one chart has nothing to do with the blue-ish group in the second
chart). Still, we can see both some similarities, as well as some
differences in how the clusters (colors) are distributed across the
chart. This type of visualization is a helpful exploratory tool for
learning more about <em>how</em> users ended up in a particular cluster.</p>
<p>Given these two algorithm choices, is one obviously better than the
other? It&#8217;s tough to say at this point. In unsupervised learning tasks
like this one, we have to assess our results against other constraints
(is simplicity important? Do we value the input data assumptions of one
model over the other?), or outside metrics (did one approach lead to
higher conversion rates?).</p>
</div>
<div class="section" id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¬∂</a></h3>
<p>Twitter is a valuable source of data about what&#8217;s happening in the
world. The rich data available through the suite of APIs provides a
detailed view into the people and content on the platform. In this
tutorial, we worked through an end-to-end example workflow - from
collecting data from the Twitter API, to creating and inspecting a model
of Twitter users. Along the way, we highlighted how to identify and use
relevant elements of the data payload, how to convert that data into a
format compatible with many machine learning libraries, and how to
inspect the resulting models for interpretability. More specifically, we
created query rules relevant to an event, collected matching JSON data,
parsed that data to extract user-specific information, applied
clustering algorithms to the text data, and looked at both textual and
graphical model output representations for interpretation.</p>
<p>Along the way, we highlighted additional opportunities to explore
variations on the specific choices we demonstrated. One of the most
important take-aways from this demo is that there are few <strong>strictly
correct</strong> choices about the data pipeline, or the model results. Rather,
the best strategy is one of experimentation and subsequent evaluation
against metrics that matter for you. Furthermore, we used a form of
unsupervised learning (clustering), which often requires a human in the
loop to review the outputs and assess for suitability. By creating good
systems for review and feedback, you can experiment and reach a valuable
outcome or result sooner.</p>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2017, twitterdev.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.5.6.<br/>
    </p>
  </div>
</footer>
  </body>
</html>
